<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://leanderhb.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://leanderhb.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-10-02T20:52:25+00:00</updated><id>https://leanderhb.github.io/feed.xml</id><title type="html">blank</title><subtitle>Pagina voor Leander Post, bevat thesis en wat ander werk. </subtitle><entry><title type="html">DV_JDDE</title><link href="https://leanderhb.github.io/update/2024/dv_jdde/" rel="alternate" type="text/html" title="DV_JDDE"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/dv_jdde</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/dv_jdde/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>Lemma 3.2 Let \(H: \mathbb{R}_{\geq 0} \rightarrow \mathbb{R}\) be such that the differential equation \(w_{x x}=\rho w-\) \(H(w), \rho&gt;0\) has a solution \(w_h\) which is homoclinic to \(\left(w, w_x\right)=(0,0)\), and write \(h(x)=H^{\prime}\left(w_h(x)\right)\). For a differential operator of the form \(\mathcal{L}(x)=\frac{d^2}{d x^2}+h(x)-\rho\), consider the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\) with boundary conditions \(\lim _{x \rightarrow \pm \infty} w(x)=0\). Moreover, define \(\Lambda=\sqrt{\rho+\lambda} ; \arg (\Lambda) \in\left(-\frac{\pi}{2}, \frac{\pi}{2}\right]\). Then the following holds: (i) There is a finite number of real eigenvalues \(\lambda_j, j=0,1, \cdots, J\) for <del>which \(\lambda_0&gt;0, \lambda_1=\) 0 and \(0&gt;\lambda_2&gt;\cdots&gt;\lambda_J&gt;-\rho\). ~~Equivalently, there is a finite number of real eigenvalues \(\Lambda_j\) for which \(\Lambda_0&gt;\sqrt{\rho}, \Lambda_1=\sqrt{\rho}\) and \(\sqrt{\rho}&gt;\Lambda_2&gt;\cdots&gt;\Lambda_J&gt;0\). (ii) The associated eigenfunctions \(w_j(x)\) have \(j\) distinct zeroes and are ~~even resp. odd as a function of \(x\) if \(j\) is even resp. odd.</del> Moreover, \(\frac{d}{d x} w_h(x)\) is an eigenfunction for \(\lambda_1=0\) \(\left(\right.\) or \(\left.\Lambda_1=1\right)\); in other words, \(w_1(x) \in \operatorname{span}\left\{\frac{d}{d x} w_h(x)\right\}\). (iii) The eigenfunctions \(w_j(x), j=0, \cdots, J\) form an orthogonal set:</p> <div class="math-container">\[ \left\langle w_j, w_k\right\rangle=\int_{-\infty}^{\infty} w_j(x) w_k(x) d x=0 \text { for } j \neq k \text {, and }\left\|w_j\right\|_2=\sqrt{\left\langle w_j, w_j\right\rangle} \neq 0 ; \]</div> <p>these eigenfunctions can be determined uniquely by the condition</p> <div class="math-container">\[ w_j(x) \sim 1 \cdot e^{-\Lambda_j x} \text { as } x \rightarrow \infty \]</div> <p>(iv) The spectrum associated to the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\) is given by \(\sigma_\lambda=(-\infty,-\rho) \cup\left\{\lambda_0, \cdots, \lambda_J\right\}\) or equivalently \(\sigma_{\Lambda}=i \mathbb{R}_{&gt;0} \cup\left\{\Lambda_0, \cdots, \Lambda_J\right\}\). (v) For every \(\lambda \notin \sigma_\lambda\), there is a unique solution \(w_\lambda^{\mathrm{R}}(x)\) (which depends smoothly on \(\lambda\) ) such that</p> <div class="math-container">\[ w_\lambda^{\mathrm{R}}(x) \sim 1 \cdot e^{-\Lambda x} \text { as } x \rightarrow \infty . \]</div> <p>Moreover, the pair \(\left\{w_\lambda^{\mathrm{R}}, w_\lambda^{\mathrm{L}}\right\}\) with \(w_\lambda^{\mathrm{L}}(x)=w_\lambda^{\mathrm{R}}(-x)\) spans the solution space of the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\).</p> <p>For (3.12) we can apply the above lemma with \(\rho=1\), obtaining a set of fast eigenvalues \(\lambda_{f, j}\) and their associated eigenfunctions \(w_{f, j}(\xi)\). Moreover, we observe that for \(\rho=1, \Lambda=\Lambda_f\) \((3.8)\). Next, we consider the Wronskian</p> <div class="math-container">\[ \mathcal{W}(\lambda) \stackrel{\text { def }}{=} \operatorname{det}\left(\begin{array}{cc} w_\lambda^{\mathrm{L}}(\xi) &amp; w_\lambda^{\mathrm{R}}(\xi) \\ \frac{d}{d \xi} w_\lambda^{\mathrm{L}}(\xi) &amp; \frac{d}{d \xi} w_\lambda^{\mathrm{R}}(\xi) \end{array}\right) \]</div> <p>associated to (3.12). For notational convenience we only consider \(\mathcal{W}\) as function of \(\lambda\) here and in the upcoming lemma. In the forthcoming analysis we will however often switch between the equivalent expressions \(\mathcal{W}(\lambda)\) and \(\mathcal{W}\left(\Lambda_f\right)\). This Wronskian can be defined as a smooth, in fact analytic, function of \(\lambda\) for all \(\lambda \in \mathbb{C}\) outside the (closure of the) essential spectrum associated to (3.12), i.e. for \(\lambda \notin(-\infty,-1]\), but including the (eigen)values \(\lambda=\lambda_{f, j}\) (Lemma 3.2), by setting \(\mathcal{W}\left(\lambda_{f, j}\right)=0, j=0, \ldots, J\) [33]. Note that \(\mathcal{W}(\lambda)\) is in fact an Evans function [1]. In combination with Lemma 3.2, the following result on \(\mathcal{W}(\lambda)\) enables us to generalize the GS/GM-type hypergeometric functions approach to the present setting.</p> <p>Lemma 3.3 Let \(\mathcal{W}(\lambda)\) be the Wronskian associated to (3.12) and let \(\lambda \notin(-\infty,-1]\), then</p> <div class="math-container">\[ \mathcal{W}(\lambda) \sim(-1)^{j+1}\left\|w_{f, j}\right\|_2^2\left(\lambda-\lambda_{f, j}\right) \quad \text { as } \quad \lambda \rightarrow \lambda_{f, j}, j=0, \ldots, J . \]</div> <p>See Fig. 5 for a sketch of a \(\mathcal{W}(\lambda)\) for real \(\lambda&gt;-1\). Proof Since we know that \(\mathcal{W}(\lambda)\) is a smooth function of \(\lambda\) near its zeroes \(\lambda_{f, j}\), the proof can be based on a (finite) Taylor expansion of \(\mathcal{W}\left(\lambda_{f, j}+\delta\right)\) for \(\delta=\lambda-\lambda_{f, j} \in \mathbb{C}\) small. To do so, we first need to approximate \(w_\lambda^{\mathrm{R}}(\xi)\) for \(\lambda=\lambda_{f, j}+\delta\). Therefore, we introduce the (regular) approximation</p> <div class="math-container">\[ w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)=w_{f, j}(\xi)+\delta w_{1, j}(\xi)+\mathcal{R}(\xi ; \delta), \]</div> <p>in which \(\mathcal{R}(\xi ; \delta)\) represents the error terms. This expansion can in general not give a valid approximation of \(w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)\) for \(\xi \rightarrow \infty\). However, it follows directly from Poincaré’s expansion theorem (see for instance [39]) that for every \(\rho \in[0,1)\) there is a positive \(\mathcal{O}(1)\) constant \(C_\rho\) such that</p> <div class="math-container">\[ \left|w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)-\left(w_{f, j}(\xi)+\delta w_{1, j}(\xi)\right)\right|=|\mathcal{R}(\xi ; \delta)|&lt;C_\rho \delta^{2(1-\rho)}, \]</div> <p>for \(|\xi|&lt;\mathcal{O}\left(\delta^{-\rho}\right)\). Note that the standard (and natural) result that \(\mathcal{R}(\xi ; \delta) \mid=\mathcal{O}\left(\delta^2\right)\) on \(\mathcal{O}(1) \xi\)-intervals corresponds to the case \(\rho=0\) in (3.17). To determine the leading order correction \(w_{1, j}(\xi)\), we substitute (3.16) into (3.12) and obtain the inhomogeneous problem</p> <div class="math-container">\[ \left(\mathcal{L}_f(\xi)-\lambda_{f, j}\right) w_{1, j}=w_{f, j}(\xi)+\mathcal{O}\left(\delta^{1-2 \rho}\right) \]</div> <p>(3.12) on the domain \(|\xi|&lt;\mathcal{O}\left(\delta^{-\rho}\right)\). It is clear that for the above to be a leading order expression, \(\rho&lt;\frac{1}{2}\) must hold. This equation cannot have a solution that is bounded on \(\mathbb{R}\), since the operator \(\mathcal{L}_f(\xi)-\lambda\) is not invertible at \(\lambda=\lambda_{f, j}\) and the inhomogeneous term \(b(\xi)=w_{f, j}(\xi)\) clearly does not satisfy the solvability condition \(\left\langle b, w_{f, j}\right\rangle=\left\langle w_{f, j}, w_{f, j}\right\rangle=\) 0 , see also Sect. 3.3. However, this is not a problem: we are constructing an approximation of a solution \(w_\lambda^{\mathrm{R}}(\xi)\) and this solution need not be bounded on \(\mathbb{R}\) for \(\lambda \neq \lambda_{f, j}\) (Lemma 3.2). Since \(w_{f, j}(\xi)\) is a solution of the homogeneous problem, we apply the variation of constants method, i.e. we introduce the unknown function \(c_j(\xi)\) by \(w_{1, j}(\xi)=c_j(\xi) w_{f, j}(\xi)\) and obtain an equation for \(c_j\) :</p> <div class="math-container">\[ \ddot{c}_j w_{f, j}+2 \dot{c}_j \dot{w}_{f, j}=w_{f, j} \]</div> <p>This implies that</p> <div class="math-container">\[ \dot{c}_j(\xi)=\frac{1}{w_{f, j}^2(\xi)}\left[\int_0^{\xi} w_{f, j}^2(\eta) d \eta+c_{1, j}\right], \]</div> <p>where \(c_{1, j}\) is a constant of integration. Writing \(c_{1, j}=\hat{c}_{1, j}-\int_0^{\infty} w_{f, j}^2(\eta) d \eta\), we investigate the behaviour of \(\dot{c}_j(\xi)\) as \(\xi \rightarrow \delta^{-\rho}\). From Lemma 3.2, we know that \(w_{f, j}(\xi) \sim e^{-\Lambda_{f, j} \delta^{-\rho}}\) as \(\xi \rightarrow \delta^{-\rho}\). Therefore,</p> <div class="math-container">\[ \begin{aligned} \dot{c}_j(\xi) \sim &amp; e^{2 \Lambda_{f, j} \delta^{-\rho}}\left[\int_0^{\delta^{-\rho}} w_{f, j}^2(\eta) d \eta-\int_0^{\infty} w_{f, j}^2(\eta) d \eta+\hat{c}_{1, j}\right] \\ &amp; =\left[-\int_{\delta^{-\rho}}^{\infty} w_{f, j}^2(\eta) d \eta+\hat{c}_{1, j}\right] e^{2 \Lambda_{f, j} \delta^{-\rho}} \\ &amp; =-\frac{1}{2 \Lambda_{f, j}}+\hat{c}_{1, j} e^{2 \Lambda_{f, j} \delta^{-\rho}} \end{aligned} \]</div> <p>as \(\xi \rightarrow \delta^{-\rho}\). Since the solution \(w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)\) (3.16) does not grow exponentially as \(\xi \rightarrow \delta^{-\rho}\) (3.14), it necessarily follows that \(w_{1, j}(\xi)\) does neither. Therefore, \(c_j(\xi)\) can at most grow as \(\frac{1}{w_{f, j}}\), which is as \(e^{\Lambda_{f, j} \xi}\). From this, it follows that \(\hat{c}_{1, j}=0\) and therefore</p> <div class="math-container">\[ c_{1, j}=-\int_0^{\infty} w_{f, j}^2(\eta) d \eta \quad \text { so that } \dot{c}_j(\xi)=-\frac{1}{w_{f, j}^2(\xi)} \int_{\xi}^{\infty} w_{f, j}^2(\eta) d \eta . \]</div> <p>We now return to the Wronskian (3.15). Since \(w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)=w_{f, j}(\xi)\left(1+\delta c_j(\xi)\right)+\mathcal{R}(\xi ; \delta)\), we can use Lemma 3.2 (ii),(v) to obtain</p> <div class="math-container">\[ \begin{aligned} w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi) &amp; =w_{f, j}(\xi)\left(1+\delta c_j(\xi)\right)+\mathcal{R}(\xi ; \delta) \\ w_{\lambda_{f, j}+\delta}^{\mathrm{L}}(\xi) &amp; =(-1)^j w_{f, j}(\xi)\left(1+\delta c_j(-\xi)\right)+\mathcal{R}(-\xi ; \delta) \\ \frac{\mathrm{d}}{\mathrm{d} \xi} w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi) &amp; =\frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi}(\xi)\left(1+\delta c_j(\xi)\right)+\delta w_{f, j}(\xi) \frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}(\xi ; \delta) \\ \frac{\mathrm{d}}{\mathrm{d} \xi} w_{\lambda_{f, j}+\delta}^{\mathrm{L}}(\xi) &amp; =(-1)^j\left[\frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi}(\xi)\left(1+\delta c_j(-\xi)\right)-\delta w_{f, j}(\xi) \frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right]-\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}(-\xi ; \delta) \end{aligned} \]</div> <p>Since \(w_\lambda^{\mathrm{L} / \mathrm{R}}(\xi)\) depends smoothly on \(\lambda\) (cf. Lemma 3.2), the Poincaré expansion theorem can be applied to \(\frac{\mathrm{d}}{\mathrm{d} \xi} w_{\lambda_{f, j}+\delta}^{\mathrm{R}}\) to obtain the result that for every \(\hat{\rho} \in[0,1)\) there is a \(C_{\hat{\rho}}\) such that \(\left|\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}(\xi ; \delta)\right|&lt;C_{\hat{\rho}} \delta^{2(1-\hat{\rho})}\). Choosing \(\hat{\rho}=\rho&lt;\frac{1}{2}\) enables us to treat \(\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}\) as a higher order term. Using the above expansions for the Wronskian, we obtain</p> <div class="math-container">\[ \begin{aligned} \mathcal{W}\left(\lambda_{f, j}+\delta\right)= &amp; (-1)^j\left(w_{f, j} \frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi}-\frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi} w_{f, j}\right)\left(1+\delta c_j(\xi)+\delta c_j(-\xi)\right) \\ &amp; +\delta(-1)^j w_{f, j}^2(\xi)\left[\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right]+\mathcal{O}\left(\delta^2\right) \\ = &amp; \delta(-1)^j w_{f, j}^2(\xi)\left[\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right]+\mathcal{O}\left(\delta^2\right), \end{aligned} \]</div> <p>in which we refrained from explicitly writing down all \(\mathcal{O}\left(\delta^2\right)=\mathcal{O}\left(\left|\lambda-\lambda_{f, j}\right|^2\right)\) correction terms. Using (3.19), we see that</p> <div class="math-container">\[ \begin{aligned} w_{f, j}^2(\xi)\left[\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right] &amp; =-\int_{\xi}^{\infty} w_{f, j}^2(\eta) \mathrm{d} \eta-\int_{-\xi}^{\infty} w_{f, j}^2(\eta) \mathrm{d} \eta=-\int_{-\infty}^{\infty} w_{f, j}^2(\eta) \mathrm{d} \eta \\ &amp; =-\left\|w_{f, j}\right\|_2^2 \end{aligned} \]</div> <p>using again Lemma 3.2 (ii).</p> <p>Clearly, the Wronskian \(\mathcal{W}(\lambda)\) has an extremum for \(\lambda \in \mathbb{R}\) between two successive eigenvalues. Based on the previous lemma it can easily be established that this extremum is a maximum between \(\lambda_{2 j+1}&lt;\lambda_{2 j}\) and a minimum between \(\lambda_{2 j}&lt;\lambda_{2 j-1}\). The following lemma determines the limit behavior of \(\mathcal{W}(\lambda)\) for \(\lambda \in \mathbb{R}\) large, see also Fig. 5.</p> <p>Lemma 3.4 Let \(\mathcal{W}(\lambda)\) be the Wronskian associated to (3.12) and let \(\lambda \in \mathbb{R} \backslash(-\infty,-1]\), then</p> <div class="math-container">\[ \mathcal{W}(\lambda) \leadsto-2 \sqrt{\lambda} \text { as } \lambda \rightarrow+\infty . \]</div> <p>Proof Define \(\delta=1 / \Lambda_f&gt;0\left(\Lambda_f \in \mathbb{R}\right)\). It can be shown by the methods of the above proof that for \(\delta\) small enough, i.e. \(\Lambda_f&gt;0\) large enough,</p> <div class="math-container">\[ w_\lambda^{\mathrm{R}}(\xi)=e^{-\Lambda_f \xi}(1+\mathcal{O}(\delta)), \quad \text { and } \quad w_\lambda^{\mathrm{L}}(\xi)=e^{\Lambda_f \xi}(1+\mathcal{O}(\delta)) . \]</div> <p>on an \(\mathcal{O}(1) \xi\)-domain \(\supset\{\xi=0\}\). Hence, for \(\Lambda_f\) large enough,</p> <div class="math-container">\[ \begin{aligned} \mathcal{W}\left(\Lambda_f\right) &amp; =\operatorname{det}\left(\begin{array}{cc} e^{\Lambda_f \xi}(1+\mathcal{O}(\delta)) &amp; e^{-\Lambda_f \xi}(1+\mathcal{O}(\delta)) \\ \Lambda_f e^{\Lambda_f \xi}(1+\mathcal{O}(\delta)) &amp; -\Lambda_f e^{-\Lambda_f \xi}(1+\mathcal{O}(\delta)) \end{array}\right) \\ &amp; =-2 \Lambda_f(1+\mathcal{O}(\delta)) \end{aligned} \]</div> <p>which is equivalent to the statement of the lemma by the definition of \(\Lambda_f\) (3.8). 3.3 The Inhomogeneous Fast Reduced Sturm-Liouville Problem</p> <p>Since the inhomogeneous problem (3.11) is linear (and can thus be rescaled), we define \(v_{\text {in }}(\xi ; \lambda)\) as the bounded solution of</p> <div class="math-container">\[ \left(\mathcal{L}_f(\xi)-\lambda\right) v=-\frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\xi ; u_*\right)\right) . \]</div> <p>Note that this is only possible if \(u(0) \neq 0\); the situation where \(u(0)=0\) will be treated in Sect. 5 (which is related to the case \(B_{-}(\lambda)=0\) there). It follows from the general theory on Sturm-Liouville problems that \(v_{\text {in }}(\xi ; \lambda)\) is uniquely determined for \(\lambda \notin \sigma_f\) ([33]). Since \(\left\{w_\lambda^{\mathrm{L}}(\xi), w_\lambda^{\mathrm{R}}(\xi)\right\}=\left\{w_\lambda^{\mathrm{R}}(-\xi), w_\lambda^{\mathrm{R}}(\xi)\right\}\) span the solution space associated to the homogeneous problem (Lemma 3.2), \(v_{\text {in }}(\xi ; \lambda)\) can be determined explicitly (in terms of \(\left.w_\lambda^{\mathrm{R}}( \pm \xi)\right)\).</p> <p>Lemma 3.5 The bounded solution of (3.25) is given by \(v_{i n}(\xi ; \lambda)=A(\xi) w_\lambda^{\mathrm{R}}(\xi)+\) \(A(-\xi) w_\lambda^{\mathrm{R}}(-\xi)\), with</p> <div class="math-container">\[ A(\xi)=A(\xi ; \lambda)=-\frac{1}{\mathcal{W}(\lambda)} \int_{-\infty}^{\xi} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_\lambda^{\mathrm{R}}(-\tilde{\xi}) d \tilde{\xi} \]</div> <p>Note that it immediately follows from this expression and assumption (A4) in combination with the properties of \(v_{f, h}\left(\xi ; u_*\right)\) that \(v_{\text {in }}(\xi ; \lambda)\) decays exponentially fast to 0 as \(\xi \rightarrow \pm \infty\) (and as \(\xi\) approaches the boundaries of \(I_f(2.7)\) ).</p> <p>Proof By the variation of constants approach, we introduce the unknown functions \(A^{\mathrm{L} / \mathrm{R}}(\xi)\) by \(v_{\text {in }}(\xi)=A^{\mathrm{L}}(\xi) w_\lambda^{\mathrm{L}}(\xi)+A^{\mathrm{R}}(\xi) w_\lambda^{\mathrm{R}}(\xi)\). Substitution in (3.25) yields</p> <div class="math-container">\[ \dot{A}^{\mathrm{L} / \mathrm{R}}=\frac{\mp 1}{\mathcal{W}(\lambda)} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\xi ; u_*\right)\right) w_\lambda^{\mp}(\xi) \]</div> <p>so that</p> <div class="math-container">\[ A^{\mathrm{L} / \mathrm{R}}(\xi)=A^{\mathrm{L} / \mathrm{R}}(0) \mp \frac{1}{\mathcal{W}(\lambda)} \int_0^{\xi} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_\lambda^{\mp}(\tilde{\xi}) d \tilde{\xi} . \]</div> <p>Both the operator \(\mathcal{L}_f(\xi)\) and the inhomogeneous term in (3.25) are even as function of \(\xi\). This implies that also \(v_{\text {in }}(\xi ; \lambda)\) must be even, so that \(A^{\mathrm{R}}(\xi)=A^{\mathrm{L}}(-\xi) \stackrel{\text { def }}{=} A(\xi)\) and \(A^{\mathrm{R}}(0)=A^{\mathrm{L}}(0)\). A straightforward analysis yields that \(v_{\text {in }}(\xi)\) can only be bounded if</p> <div class="math-container">\[ A(0)=-\frac{1}{\mathcal{W}(\lambda)} \int_{-\infty}^0 \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_\lambda^{\mathrm{L}}(\tilde{\xi}) d \tilde{\xi} \]</div> <p>which is a converging integral by assumption (A4). A priori, there is a singularity in the solutions \(v_{\text {in }}(\xi ; \lambda)\) as \(\lambda \rightarrow \lambda_{f, j}\), due to the fact that \(\left(\mathcal{L}_f(\xi)-\lambda\right)\) is not invertible at \(\lambda_{f, j}\) (and that thus \(\mathcal{W}\left(\lambda_{f, j}\right)=0\), Lemma 3.3). However, by the Fredholm alternative, (3.25) will have solutions for \(\lambda=\lambda_{f, j}\) with \(j\) odd, since \(w_{f, j}(\xi)\) is odd as function of \(\xi\) (Lemma 3.2) and the (even) inhomogeneity of (3.25) thus satisfies the solvability condition.</p> <p>Corollary 3.6 For \(j\) even,</p> <div class="math-container">\[ v_{i n}(\xi ; \lambda) \sim\left(\frac{w_{f, j}(\xi)}{\left\|w_{f, j}\right\|_2^2} \int_{-\infty}^{\infty} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_{f, j}(\tilde{\xi}) d \tilde{\xi}\right) \cdot \frac{1}{\lambda-\lambda_{f, j}} \text { as } \lambda \rightarrow \lambda_{f, j}, \]</div> <p>while \(\lim _{\lambda \rightarrow \lambda_{f, j}} v_{i n}(\xi ; \lambda)\) exists for \(j\) odd. Proof Using the fact that \(w_{f, j}(\xi)\) is even/odd as function of \(\xi\) for \(j\) even/odd, identity (3.27) can be obtained directly by combining Lemmas 3.3 and 3.5, both for \(j\) even and for \(j\) odd—in the latter case, the integral in (3.27) vanishes.</p> <p>It will be necessary to also have an explicit characterization of \(v_{\text {in }}(\xi ; \lambda)\) for \(\lambda\) near \(\lambda_{f, 1}\), the crucial (odd) case \(j=1\) for which \(\lambda_{f, 1}=0\).</p> <p>Lemma 3.7 For \(\lambda=\lambda_{f, 1}=0, v_{\text {in }}(\xi ; \lambda)\) is not uniquely determined: here,</p> <div class="math-container">\[ v_{i n}(\xi ; 0)=\left.\frac{\partial}{\partial u} v_{f, h}(\xi ; u)\right|_{u=u_*}+C \dot{v}_{f, h}\left(\xi ; u_*\right) \]</div> <p>in which \(C \in \mathbb{R}\) is a free parameter. It is also possible to obtain leading order approximations of \(v_{\text {in }}(\xi ; \lambda)\) for \(\lambda\) near \(\lambda_{f, j}\) with \(j \geq 3\) odd. However, we refrain from going into these details.</p> <p>Proof The fact that</p> <div class="math-container">\[\left.\frac{\partial}{\partial u} v_{f, h}(\xi ; u)\right|_{u=u_*}\]</div> <p>is a solution of (3.25) follows immediately from taking the derivative with respect to the parameter \(u\) (or \(u_0\) ) in (2.3). Uniqueness is lost by adding the kernel \(\dot{v}_{f, h}\left(\xi ; u_*\right)\) associated to the operator \(\mathcal{L}_f(\xi)\).</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Lemma 3.2 Let \(H: \mathbb{R}_{\geq 0} \rightarrow \mathbb{R}\) be such that the differential equation \(w_{x x}=\rho w-\) \(H(w), \rho&gt;0\) has a solution \(w_h\) which is homoclinic to \(\left(w, w_x\right)=(0,0)\), and write \(h(x)=H^{\prime}\left(w_h(x)\right)\). For a differential operator of the form \(\mathcal{L}(x)=\frac{d^2}{d x^2}+h(x)-\rho\), consider the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\) with boundary conditions \(\lim _{x \rightarrow \pm \infty} w(x)=0\). Moreover, define \(\Lambda=\sqrt{\rho+\lambda} ; \arg (\Lambda) \in\left(-\frac{\pi}{2}, \frac{\pi}{2}\right]\). Then the following holds: (i) There is a finite number of real eigenvalues \(\lambda_j, j=0,1, \cdots, J\) for which \(\lambda_0&gt;0, \lambda_1=\) 0 and \(0&gt;\lambda_2&gt;\cdots&gt;\lambda_J&gt;-\rho\). ~~Equivalently, there is a finite number of real eigenvalues \(\Lambda_j\) for which \(\Lambda_0&gt;\sqrt{\rho}, \Lambda_1=\sqrt{\rho}\) and \(\sqrt{\rho}&gt;\Lambda_2&gt;\cdots&gt;\Lambda_J&gt;0\). (ii) The associated eigenfunctions \(w_j(x)\) have \(j\) distinct zeroes and are ~~even resp. odd as a function of \(x\) if \(j\) is even resp. odd. Moreover, \(\frac{d}{d x} w_h(x)\) is an eigenfunction for \(\lambda_1=0\) \(\left(\right.\) or \(\left.\Lambda_1=1\right)\); in other words, \(w_1(x) \in \operatorname{span}\left\{\frac{d}{d x} w_h(x)\right\}\). (iii) The eigenfunctions \(w_j(x), j=0, \cdots, J\) form an orthogonal set: \[ \left\langle w_j, w_k\right\rangle=\int_{-\infty}^{\infty} w_j(x) w_k(x) d x=0 \text { for } j \neq k \text {, and }\left\|w_j\right\|_2=\sqrt{\left\langle w_j, w_j\right\rangle} \neq 0 ; \] these eigenfunctions can be determined uniquely by the condition \[ w_j(x) \sim 1 \cdot e^{-\Lambda_j x} \text { as } x \rightarrow \infty \] (iv) The spectrum associated to the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\) is given by \(\sigma_\lambda=(-\infty,-\rho) \cup\left\{\lambda_0, \cdots, \lambda_J\right\}\) or equivalently \(\sigma_{\Lambda}=i \mathbb{R}_{&gt;0} \cup\left\{\Lambda_0, \cdots, \Lambda_J\right\}\). (v) For every \(\lambda \notin \sigma_\lambda\), there is a unique solution \(w_\lambda^{\mathrm{R}}(x)\) (which depends smoothly on \(\lambda\) ) such that \[ w_\lambda^{\mathrm{R}}(x) \sim 1 \cdot e^{-\Lambda x} \text { as } x \rightarrow \infty . \]]]></summary></entry><entry><title type="html">Grid based derivation</title><link href="https://leanderhb.github.io/update/2024/grid-based-derivation/" rel="alternate" type="text/html" title="Grid based derivation"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/grid-based-derivation</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/grid-based-derivation/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>If the plant is there and the food is there, there’s a certain probability of the plant uptaking the food. Also, plant have a certain chance of “duplicating”, by taking up the food. Besides that, the plants and the food do a random walk with a certain rate.</p> <ul> <li>plant eats food: \(P+F \xrightarrow{\alpha(P,F)} 2P\)</li> <li>plant dies: \(P\xrightarrow{\beta(P,F)} F\)</li> <li>plant hops: \(P_i \xrightarrow{d_P}P_{i\pm 1}\)</li> <li>food hops: \(F_i \xrightarrow{d_F}F_{i\pm 1}\) We do the classic thing of finding how the probability at a site changes:</li> </ul> <div class="math-container">\[\begin{aligned} \frac{dP_i}{dt} = \underbrace{d_P\left( P_{i-1}+P_{i+1} \right)}_{\text{hopping to i}}-\underbrace{2d_PP_i}_{\text{hopping away}}+\underbrace{\alpha(P,F)PF}_{\text{plant duplicates}}-\underbrace{\beta(P,F) P}_{\text{plant dies}}\\ \frac{dF_i}{dt} = \underbrace{d_F\left( F_{i-1}+F_{i+1} \right)}_{\text{hopping to i}}-\underbrace{2d_FF_i}_{\text{hopping away}}-\underbrace{\alpha(P,F)PF}_{\text{food eaten}}+\underbrace{\beta(P,F) P}_{\text{new food}} \end{aligned}\]</div> <p>Taking the continuum limit, we get:</p> <div class="math-container">\[\begin{aligned} P_t = D_P P_{xx}+\alpha(P,F)PF-\beta(P,F) P\\ F_t = D_F F_{xx}-\alpha(P,F)PF+\beta(P,F) P \end{aligned}\]</div> <p>More generally, with a bit of rescaling, we get:</p> <div class="math-container">\[\begin{aligned} U_t&amp;=D U_{xx}+f(U,V)\\ V_t &amp;=V_{xx}-f(U,V) \end{aligned}\]</div> <p>with \(f\) now a general function of \(U\) and \(V\), now some generalized concentrations.</p> <p>This is called a reaction diffusion system, with conserved concentration :)</p> <h1 id="slides-for-fourier">Slides for fourier</h1> <p>Integral should have a real value. Then the left hand side should be real too. Then for positive, real \(\lambda\), we require that the square roots be real. If they aren’t, we can’t have positive, real \(\lambda\), which is interesting. This implies:</p> <div class="math-container">\[ f_{V,r}&lt;f_{U,r},\quad f_{V,l}&lt;f_{U,l} \]</div> <p>is necessary for instability in the form of a real (non-oscillating) eigenvalue.</p> <p>Let’s check the stability around \((U_+,V_+)\). We linearize again:</p> <div class="math-container">\[ \begin{aligned} u_t &amp;= \epsilon^2 u_{xx}+f_U(U_+,V_+)u+f_V(U_+,V_+)v\\ v_t &amp;= v_{xx}-f_U(U_+,V_+)u-f_V(U_+,V_+)v \end{aligned} \]</div> <p>A quick Fourier transform (we assume we’re far away enough from any structure that we can do this, other words, the slow reduced system), shows us that:</p> <div class="math-container">\[\begin{aligned} \hat{u}_t = \epsilon^2(ik)^2\hat{u}+f_U \hat{u}+f_V\hat{v}\\ \hat{v}_t = (ik)^2\hat{v}-f_U\hat{u}-f_V\hat{v} \end{aligned} \]</div> <p>We now write this as:</p> <div class="math-container">\[ \begin{pmatrix}\hat{u}\\\hat{v}\end{pmatrix}_t= \begin{pmatrix}f_U-\epsilon^2k^2&amp;f_V\\-f_U&amp;-f_V-k^2\end{pmatrix} \begin{pmatrix}\hat{u}\\\hat{v}\end{pmatrix} \]</div> <p>Which has determinant:</p> <div class="math-container">\[\begin{aligned} \Delta\begin{pmatrix}f_U-\epsilon^2k^2&amp;f_V\\-f_U&amp;-f_V-k^2\end{pmatrix} &amp;=(f_U-\epsilon^2k^2)(-f_V-k^2)+f_Uf_V \\ &amp;= -f_Uk^2+\epsilon^2 k^2 f_V+ \epsilon^2k^4\\ &amp;= k^2(\epsilon^2 k^2+\epsilon^2 f_V-f_U) \end{aligned}\]</div> <p>We require the determinant to be positive for non-growing waves. We see that a bifurcation happens, if it does at all, for \(k=0\), since that makes the determinant closest to 0. Then we find that for stability of all wavenumbers, we need \(\epsilon^2 f_V-f_U&gt;0\). Next, we look at the trace, and find that</p> <div class="math-container">\[ \operatorname{Tr}\begin{pmatrix}f_U-\epsilon^2k^2&amp;f_V\\-f_U&amp;-f_V-k^2\end{pmatrix} =f_U-\epsilon^2k^2-f_V-k^2 \]</div> <p>For stability, we require \(\operatorname{Tr}&lt;0\), so here we get another inequality for stability:</p> <div class="math-container">\[ f_V-f_U&gt;0 \]</div>]]></content><author><name></name></author><summary type="html"><![CDATA[If the plant is there and the food is there, there’s a certain probability of the plant uptaking the food. Also, plant have a certain chance of “duplicating”, by taking up the food. Besides that, the plants and the food do a random walk with a certain rate. plant eats food: \(P+F \xrightarrow{\alpha(P,F)} 2P\) plant dies: \(P\xrightarrow{\beta(P,F)} F\) plant hops: \(P_i \xrightarrow{d_P}P_{i\pm 1}\) food hops: \(F_i \xrightarrow{d_F}F_{i\pm 1}\) We do the classic thing of finding how the probability at a site changes: \[\begin{aligned} \frac{dP_i}{dt} = \underbrace{d_P\left( P_{i-1}+P_{i+1} \right)}_{\text{hopping to i}}-\underbrace{2d_PP_i}_{\text{hopping away}}+\underbrace{\alpha(P,F)PF}_{\text{plant duplicates}}-\underbrace{\beta(P,F) P}_{\text{plant dies}}\\ \frac{dF_i}{dt} = \underbrace{d_F\left( F_{i-1}+F_{i+1} \right)}_{\text{hopping to i}}-\underbrace{2d_FF_i}_{\text{hopping away}}-\underbrace{\alpha(P,F)PF}_{\text{food eaten}}+\underbrace{\beta(P,F) P}_{\text{new food}} \end{aligned}\] Taking the continuum limit, we get: \[\begin{aligned} P_t=D_P P_{xx}+\alpha(P,F)PF-\beta(P,F) P\\ F_t=D_F F_{xx}-\alpha(P,F)PF+\beta(P,F) P \end{aligned}\] More generally, with a bit of rescaling, we get: \[\begin{aligned} U_t&amp;=D U_{xx}+f(U,V)\\ V_t &amp;=V_{xx}-f(U,V) \end{aligned}\] with \(f\) now a general function of \(U\) and \(V\), now some generalized concentrations.]]></summary></entry><entry><title type="html">Meeting tips</title><link href="https://leanderhb.github.io/update/2024/meeting-tips/" rel="alternate" type="text/html" title="Meeting tips"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/meeting-tips</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/meeting-tips/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <h3 id="arjen">arjen</h3> <p>dakje eraf: kleine letter</p> <p>pulsen: kleine mu op K, zodat vergelijken met wat we nu hebben,</p> <p>afgeleide naar mu: nieuwe eigenwaarde?</p> <h3 id="mazi">mazi</h3> <p>kpz</p> <p>simulate radial</p>]]></content><author><name></name></author><summary type="html"><![CDATA[arjen dakje eraf: kleine letter]]></summary></entry><entry><title type="html">Nu is twee!</title><link href="https://leanderhb.github.io/update/2024/nu-is-twee!/" rel="alternate" type="text/html" title="Nu is twee!"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/nu-is-twee!</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/nu-is-twee!/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <h2 id="nu-order-2-slow">Nu order 2 Slow</h2> <p>We now look at the slow system, where:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat u =\epsilon^2 \hat u_{xx}+f_u^*(u^*_0,K_0^*)\hat u+f_v^*(u^*_0,K_0^*)\hat v \\ \hat\lambda \epsilon^{2} \hat v = \hat v_{xx}- f_u^*(u^*_0,K_0^*)\hat u- f_v^*(u^*_0,K_0^*)\hat v \end{aligned} \]</div> <p>We find that: Well we require the orders to match so let’s substitute \(\hat u=\epsilon^2 \hat{\hat u}\) (why u?? I guess to match \(\hat v\)) and \(\hat v=\epsilon^2 \hat{\hat v}\). This doesn’t really change the equations much:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat{\hat u} =\epsilon^2 \hat{\hat u}_{xx}+f_u^*(u^*_0,K_0^*)\hat{\hat u}+f_v^*(u^*_0,K_0^*)\hat{\hat v} \\ \hat\lambda \epsilon^{2} \hat{\hat v} = \hat{\hat v}_{xx}- f_u^*(u^*_0,K_0^*)\hat{\hat u}- f_v^*(u^*_0,K_0^*)\hat{\hat v } \end{aligned} \]</div> <p>Now we find:</p> <div class="math-container">\[ \hat{\hat u} =- \frac{f_v^*}{f_u^*}\hat{\hat v}+\mathcal O(\epsilon^2) \]</div> <p>Because of the constant coefficients, we also get \(\hat{\hat u}_{xx}= - \frac{f_v^*}{f_u^*}\hat{\hat v}_{xx}\) (is this true? can’t higher order terms have \(O(\epsilon^-1)\) derivatives or something like that?) Then we also find by adding the two equations:</p> <div class="math-container">\[ \hat{\hat v}_{xx} =\hat\lambda \epsilon^2(\hat{\hat u}+\hat{\hat v})-\epsilon^2 \hat u_{xx}=\hat\lambda\epsilon^2\frac{f_u^*-f_v^*}{f_u}\hat{\hat v^*}+ \epsilon^2\frac{f_v^*}{f_u^*}\hat{\hat v}_{xx}+\mathcal O(\epsilon^4) \]</div> <p>So we get:</p> <div class="math-container">\[ \hat{\hat v}_{xx}\left(1+\epsilon^2\frac{f_v^*}{f_u^*}\right) =\hat\lambda\epsilon^2\frac{f_u^*-f_v^*}{f_u}\hat{\hat v^*}+\mathcal O(\epsilon^4) \]</div> <p>Now we can just divide by this new term, and get the same expression as for \(2&lt;2\):</p> <div class="math-container">\[ \hat{\hat v}_{xx} =\hat\lambda\epsilon^2\frac{f_u^*-f_v^*}{f_u}\hat{\hat v^*}+\mathcal O(\epsilon^4) \]</div> <h4 id="nu-order-2-fast">Nu order 2 fast</h4> <div class="math-container">\[\begin{aligned} \hat\lambda \epsilon^2 \hat u = \hat u_{\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u+f_v^*(u^*_0,K_0^*)\hat v \\ \hat\lambda \epsilon^{2+2} \hat v = \hat v_{\xi\xi}-\epsilon^2 f_u^*(u^*_0,K_0^*)\hat u-\epsilon^2 f_v^*(u^*_0,K_0^*)\hat v \end{aligned}\]</div> <p>So: \(\hat v=\hat K+\mathcal O(\epsilon^2)\) Then we get the following system:</p> <div class="math-container">\[ \hat\lambda \epsilon^2 \hat u = \hat u_{\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u+f_v^*(u^*_0,K_0^*)\hat K+\mathcal O(\epsilon^2) \\ \]</div> <p>We expand \(\hat u\) as:</p> <div class="math-container">\[\hat u=\hat u_0+\epsilon^2\hat u_1\]</div> <p>and \(\hat K\) as \(\hat K = \epsilon^2 \hat{\hat K}\), order 1 is not possible because of the solvability criterion (Appendix). And obtain at leading order:</p> <div class="math-container">\[ \hat u_{0,\xi\xi}+f_u^*(u_0^*,K_0^*)\hat u_0=0 \]</div> <p>Which we recognize as the homogeneous fast reduced problem, to which \(Au_{0,\xi}^*\) is the solution. For simplicity we set \(A=1\) so we get \(\hat u= u^*_{0,\xi}+\epsilon^2\hat u_1\) So we get at order \(\epsilon^2\):</p> <div class="math-container">\[ \hat\lambda u^*_{0,\xi} = \hat u_{1,\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u_1+f_v^*(u^*_0,K_0^*)\hat{\hat K}+\mathcal O(\epsilon^{2}) \\ \]</div> <p>Which is a homogeneous SL problem with again the same operator \(\mathcal L=\partial_{\xi\xi}+f_u^*(u_0^*,K_0^*)\). The Fredholm alternative tells us that this equations has solutions which obey:</p> <div class="math-container">\[ \langle u_{0,\xi}^*, \hat\lambda u^*_{0,\xi} -f_v^*(u^*_0,K_0^*)\hat{\hat K} \rangle =0 \]</div> <p>Which gives:</p> <div class="math-container">\[ \hat{\hat K} = \hat\lambda \frac{\int_I (u_{0,\xi}^*(\xi))^2d\xi}{\int_I f_v^*(u_0^*(\xi),K_0^*)u_{0,\xi}^*(\xi)d\xi} \]</div> <p>Since \(u_{0,\xi}^*(\xi)\) decays exponentially on both sides, the integrals converge and can be replaced by integrals over the entirety of \(\mathbb R\).</p> <h3 id="andere-techniek-voor-fast-jump-">Andere techniek voor fast jump? :)</h3> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat u = \hat u_{\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u+\epsilon^{2}f_v^*(u^*_0,K_0^*)\hat{\hat v} \\ \hat\lambda \epsilon^{4} \hat{\hat v} = \epsilon^0 \hat{\hat v}_{\xi\xi}-\epsilon^0 f_u^*(u^*_0,K_0^*)\hat u- \epsilon^{2} f_v^*(u^*_0,K_0^*)\hat{\hat v } \end{aligned} \]</div> <p>Again our favorite trick: we add the equations and get:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat u +\hat\lambda \epsilon^{4} \hat{\hat v}= \hat u_{\xi\xi}+\epsilon^0 \hat{\hat v}_{\xi\xi}\end{aligned} \]</div> <p>We expand \(\hat u\) and find:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 (u_{0,\xi}^*+\epsilon^2\hat u_1) +\hat\lambda \epsilon^{4} \hat{\hat v}= (u_{0,\xi}^*+\epsilon^2\hat u_1)_{\xi\xi}+\epsilon^0 \hat{\hat v}_{\xi\xi}\end{aligned} \]</div> <p>Integrating this equation, and using the fact that \(u_{0,\xi}^0\) is a heteroclinic orbit, hence the derivatives go to zero for \(\xi\to\pm \infty\), we find:</p> <div class="math-container">\[ \Delta_{fast} \hat{\hat v}_\xi=\begin{aligned} \int\hat{\hat v}_{\xi\xi}d\xi=\epsilon^2\int \hat\lambda u_{0,\xi}^*- \hat u_{1,\xi\xi}d\xi+\mathcal O(\epsilon^4) \end{aligned} \]</div> <p>Note how the integral over the correction might have something to do with the interaction term! The difference in derivatives will be matched to \(\lambda\), hence (possibly) connecting to the velocity of the wave too!</p> <p>From <a href="/update/2024/arjen-notes-(my-interpretation)/">Arjen Notes (my interpretation)</a> we know that:</p> <div class="math-container">\[ \hat\lambda u^*_{0,\xi} = \hat u_{1,\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u_1+f_v^*(u^*_0,K_0^*)\hat{\hat K}+\mathcal O(\epsilon^{2}+\epsilon^{2\nu}) \]</div> <p>As the order \(\epsilon^2\) equation for \(u\). Solving for \(\hat u_1\) and inserting in the equation above then yields:</p> <div class="math-container">\[ \begin{aligned} \Delta_{fast} \hat{\hat v}_\xi=\epsilon^2\int f_u^*(u^*_0,K_0^*)\hat u_1+f_v^*(u^*_0,K_0^*)\hat{\hat K}d\xi+\mathcal O(\epsilon^4) \end{aligned} \]</div> <p>We get an integral condition on the fast jump, which we match to the square root business we found earlier.</p> <p>We get the same equation as Arjen, except the lambda term, but I think he forgot an \(\epsilon^\nu\) there. :)</p> <p>Probleem: integraal convergeert over het algemeen niet? :((</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">3.1.11</title><link href="https://leanderhb.github.io/update/2024/3.1.11/" rel="alternate" type="text/html" title="3.1.11"/><published>2024-10-01T00:00:00+00:00</published><updated>2024-10-01T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/3.1.11</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/3.1.11/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>Theorem 3.1.11. Assume that operator \(\mathcal{L}\) given in (3.1.1) is exponentially asymptotic with \(H^1(\mathbb{R})\) coefficients. Then \(\mathcal{L}\) is a relatively compact perturbation of the asymptotic operator \(\mathcal{L}_{\infty}\) given in (3.1.2). In particular,</p> <div class="math-container">\[ \sigma_{\text {ess }}(\mathcal{L})=\left\{\lambda \in \mathbb{C} \mid i_{-}(\lambda) \neq \mathrm{i}_{+}(\lambda)\right\} \cup\left\{\lambda \in \mathbb{C} \mid \operatorname{dim} \mathbb{E}^{\mathrm{c}}\left(A_{ \pm}(\lambda)\right) \neq 0\right\} \]</div> <p>Moreover, for each \(\lambda \notin \sigma_{\text {ess }}(\mathcal{L})\), either \(\operatorname{dim}(\operatorname{ker}(\mathcal{L}-\lambda)) \neq 0\) or there exists \(C&gt;0\) such that</p> <div class="math-container">\[ \left\|(\mathcal{L}-\lambda)^{-1} f\right\|_{H^n(\mathbb{R})} \leq C\|f\|_{L^2(\mathbb{R})} \]</div> <p>Proof. We consider only the case that the coefficients \(a_j(x)\) of \(\mathcal{L}\) are constant except on a common, compact interval \(I \subset \mathbb{R}\). To see that \(\mathcal{L}\) is a relatively compact perturbation of \(\mathcal{L}_{\infty}\), fix \(\lambda \in \rho\left(\mathcal{L}_{\infty}\right)\) and observe that the \(n\) th-order derivatives in \(\mathcal{L}_{\infty}-\mathcal{L}\) cancel, and setting aside the discontinuity at \(x=0\), we view the operator \(\mathcal{L}_{\infty}-\mathcal{L}\) as a piecewise map from \(H^n(\mathbb{R})\) into \(H^1\left(\mathbb{R}_{+}\right)\)and into \(H^1\left(\mathbb{R}_{-}\right)\). From Lemma 3.1 .10 we know that \(\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}: L^2(\mathbb{R}) \mapsto H^n(\mathbb{R})\) is continuous, so that the composite map \(\left(\mathcal{L}_{\infty}-\mathcal{L}\right)\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}: L^2(\mathbb{R}) \mapsto\) \(H^1\left(\mathbb{R}_{+}\right) \oplus H^1\left(\mathbb{R}_{-}\right)\)is continuous. Since the coefficients \(a_j(x)\) of \(\mathcal{L}\) are constant off \(I \subset \mathbb{R},\left(\mathcal{L}_{\infty}-\mathcal{L}\right)\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}: L^2(\mathbb{R}) \mapsto H^1\left(I_{+}\right) \oplus H^1\left(I_{-}\right)\)where \(I_{-}=I \cap(-\infty, 0]\) and \(I_{+}=I \cap[0, \infty)\). In particular the map takes bounded sets to bounded sets. As bounded sets in \(H^1\left(I_{ \pm}\right)\) are equicontinuous and \(I_{ \pm}\)are compact, we deduce from the Arzela-Ascoli theorem that the operator \(\left(\mathcal{L}_{\infty}-\mathcal{L}\right)\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}\) maps bounded sets of \(L^2(\mathbb{R})\) into precompact sets, and hence is compact. The characterization of the essential spectrum of \(\mathcal{L}\) follows from the Weyl’s essential spectrum Theorem 2.2.6 and Lemma 3.1.10. The statement (3.1.17) follows from the Fredholm alternative since \(\mathcal{L}-\lambda: H^n(\mathbb{R}) \rightarrow L^2(\mathbb{R})\) is Fredholm of index zero for \(\lambda \notin \sigma_{\text {ess }}(\mathcal{L})\).</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Theorem 3.1.11. Assume that operator \(\mathcal{L}\) given in (3.1.1) is exponentially asymptotic with \(H^1(\mathbb{R})\) coefficients. Then \(\mathcal{L}\) is a relatively compact perturbation of the asymptotic operator \(\mathcal{L}_{\infty}\) given in (3.1.2). In particular, \[ \sigma_{\text {ess }}(\mathcal{L})=\left\{\lambda \in \mathbb{C} \mid i_{-}(\lambda) \neq \mathrm{i}_{+}(\lambda)\right\} \cup\left\{\lambda \in \mathbb{C} \mid \operatorname{dim} \mathbb{E}^{\mathrm{c}}\left(A_{ \pm}(\lambda)\right) \neq 0\right\} \]]]></summary></entry><entry><title type="html">Proberen operator als perturbed</title><link href="https://leanderhb.github.io/update/2024/proberen-operator-als-perturbed/" rel="alternate" type="text/html" title="Proberen operator als perturbed"/><published>2024-10-01T00:00:00+00:00</published><updated>2024-10-01T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/proberen-operator-als-perturbed</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/proberen-operator-als-perturbed/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <div class="math-container">\[ \mathcal L = \mathcal L_0+\epsilon \mathcal L_1+\dots \]</div> <div class="math-container">\[ \lambda\begin{pmatrix}u\\v\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u\\v\end{pmatrix} \]</div> <p>expanding:</p> <div class="math-container">\[ (\lambda_0+\epsilon^2\lambda_1+\dots)\begin{pmatrix}u_0+\epsilon^2 u_1+\dots\\ v_0+\epsilon^2 v_1+\epsilon^4 v_2+\dots\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ \epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u_0+\epsilon^2 u_1+\dots\\ v_0+\epsilon^2 v_1+\epsilon^4 v_2+\dots\end{pmatrix} \]</div> <p>collecting powers</p> <div class="math-container">\[ \lambda\begin{pmatrix}u\\v\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ 0&amp;\partial_{\xi\xi} \end{pmatrix} \begin{pmatrix}u\\v\end{pmatrix} \]</div> <div class="math-container">\[ \lambda\begin{pmatrix}v+\epsilon^2 u\\v\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u\\v\end{pmatrix} \]</div> <p>dus:</p> <div class="math-container">\[ \mathcal L = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \]</div> <div class="math-container">\[ v+\epsilon^2 u = \epsilon^2\partial_{\xi\xi} u+\partial_{\xi\xi}v+0 \]</div> <h1 id="expansion">expansion</h1> <div class="math-container">\[ \lambda_0\begin{pmatrix}u_0\\ u_0+v_1\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;0 \\ 0&amp;\partial_{\xi\xi} \end{pmatrix} \begin{pmatrix}u_0\\u_0+ v_1\end{pmatrix} \]</div> <div class="math-container">\[ \hat\lambda \begin{pmatrix}u_1\\ u_1+v_2\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U-f_V^*&amp;f_V^* \\ 0&amp;\partial_{\xi\xi} \end{pmatrix} \begin{pmatrix}u_1\\u_1+ v_2\end{pmatrix} \]</div> <p>Got it! You want to express the original system in the form of a first-order differential equation involving a 4-component vector. Let’s proceed.</p> <p>We start by rewriting the system in a way that uses a first-order form for (\partial_\xi). Define:</p> <p>[ \mathbf{p} = \begin{pmatrix} u \ v \ u_\xi \ v_\xi \end{pmatrix} ]</p> <p>Now, differentiate (\mathbf{p}) with respect to (\xi):</p> <p>[ \mathbf{p}<em>\xi = \begin{pmatrix} u</em>\xi \ v_\xi \ u_{\xi\xi} \ v_{\xi\xi} \end{pmatrix} ]</p> <p>We know the original equations involve second-order derivatives of (u) and (v). Rewrite them to relate these to the components of (\mathbf{p}):</p> <p>From:</p> <ol> <li>(\lambda u = (\partial_{\xi\xi} + f^<em>_U) u + f_V^</em> v)</li> </ol> <p>We can express the second derivative (u_{\xi\xi}) as:</p> <p>[ u_{\xi\xi} = \lambda u - f^<em>_U u - f_V^</em> v ]</p> <p>Similarly, from:</p> <ol> <li>(\lambda v = -\epsilon^2 f^<em>_U u + (\partial_{\xi\xi} - \epsilon^2 f_V^</em>) v)</li> </ol> <p>We get:</p> <p>[ v_{\xi\xi} = \lambda v + \epsilon^2 f^<em>_U u + \epsilon^2 f_V^</em> v ]</p> <p>Now, we can write this in matrix form as:</p> <p>[ \mathbf{p}_\xi = A \mathbf{p} ]</p> <p>where:</p> <p>[ A = \begin{pmatrix} 0 &amp; 0 &amp; 1 &amp; 0 <br/> 0 &amp; 0 &amp; 0 &amp; 1 <br/> \lambda - f^<em>_U &amp; -f_V^</em> &amp; 0 &amp; 0 <br/> \epsilon^2 f^<em>_U &amp; \lambda + \epsilon^2 f_V^</em> &amp; 0 &amp; 0 \end{pmatrix} ]</p> <p>Thus:</p> <p>[ \mathbf{p}_\xi = A \mathbf{p} ]</p> <p>This expresses the original system as a first-order differential equation in terms of a 4-component vector (\mathbf{p}).</p>]]></content><author><name></name></author><summary type="html"><![CDATA[\[ \mathcal L=\mathcal L_0+\epsilon \mathcal L_1+\dots \] \[ \lambda\begin{pmatrix}u\\v\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u\\v\end{pmatrix} \] expanding: \[ (\lambda_0+\epsilon^2\lambda_1+\dots)\begin{pmatrix}u_0+\epsilon^2 u_1+\dots\\ v_0+\epsilon^2 v_1+\epsilon^4 v_2+\dots\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ \epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u_0+\epsilon^2 u_1+\dots\\ v_0+\epsilon^2 v_1+\epsilon^4 v_2+\dots\end{pmatrix} \]]]></summary></entry><entry><title type="html">Weyl voor niet-compact poging</title><link href="https://leanderhb.github.io/update/2024/weyl-voor-niet-compact-poging/" rel="alternate" type="text/html" title="Weyl voor niet-compact poging"/><published>2024-10-01T00:00:00+00:00</published><updated>2024-10-01T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/weyl-voor-niet-compact-poging</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/weyl-voor-niet-compact-poging/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <div class="math-container">\[ \mathcal L-\mathcal L_\infty \]</div> <div class="math-container">\[ \mathcal L = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \]</div> <p>Dus:</p> <div class="math-container">\[ \mathcal L-\mathcal L_\infty = \begin{pmatrix}f^*_U(x)-&amp;f_V^*(x) \\ -f^*_U(x)&amp;f_V^*- f_V^*(x) \end{pmatrix} \]</div> <div class="math-container">\[ \mathcal L-\mathcal L_\infty = \begin{pmatrix}a(x)-a_\pm&amp;b(x)-b_\pm \\ -a(x)+a_\pm&amp;-b(x)+b_\pm \end{pmatrix} \]</div> <div class="math-container">\[ (\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}(u,v) = \]</div> <div class="math-container">\[ \|(\mathcal L_\infty-\lambda)^{-1}\| \leq C(\lambda)\|f\| \]</div> <p>Take weakest decay in \(\mathcal L-\mathcal L_\infty\), call it \(\alpha\), then:</p> <div class="math-container">\[ \|(\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}w \|\leq \|(\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}w \| \]</div> <div class="math-container">\[ \int |(\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}w |^2dx= \]</div>]]></content><author><name></name></author><summary type="html"><![CDATA[\[ \mathcal L-\mathcal L_\infty \] \[ \mathcal L=\begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \] Dus: \[ \mathcal L-\mathcal L_\infty = \begin{pmatrix}f^*_U(x)-&amp;f_V^*(x) \\ -f^*_U(x)&amp;f_V^*- f_V^*(x) \end{pmatrix} \]]]></summary></entry><entry><title type="html">Slow eqns netjes</title><link href="https://leanderhb.github.io/update/2024/slow-eqns-netjes/" rel="alternate" type="text/html" title="Slow eqns netjes"/><published>2024-09-30T00:00:00+00:00</published><updated>2024-09-30T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/slow-eqns-netjes</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/slow-eqns-netjes/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>For the slow equations, we introduce \(X=\epsilon x\). Then the (superslow) equations become:</p> <div class="math-container">\[ \begin{aligned} \epsilon^2 \hat\lambda u &amp; = \epsilon^4u_{XX}+[f_U^* +\epsilon^2f_{UU}^* U_1^*+\epsilon^2f_{UV}^* (K_1^*-U_0^*)]u \\ &amp; +[f_V^* +\epsilon^2f_{VU}^* U_1^*+\epsilon^2f_{VU}^* (K^*_1-U_0^*)]v+\mathcal O(\epsilon^4) \\ \epsilon^2 \hat\lambda v &amp; = \epsilon^2 v_{XX}+[-f_U^* -\epsilon^2f_{UU}^* U_1^*-\epsilon^2f_{UV}^* (K_1^*-U_0^*)]u \\ &amp; +[-f_V^* -\epsilon^2f_{VU}^* U_1^*-\epsilon^2f_{VU}^* (K^*_1-U_0^*)]v+\mathcal O(\epsilon^4) \\ \end{aligned} \]</div> <p>Everything is exponentially close to constant. Both equations give at leading order:</p> <div class="math-container">\[ u = -\frac{f_V^*}{f_U^*}v \]</div> <p>Now we add the equations and find at the next order:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda u+\hat\lambda v &amp; =v_{XX} \end{aligned} \]</div> <p>Then:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda\frac{f_U^*-f_V^*}{f_U^*} v &amp; = v_{XX} \end{aligned} \]</div> <p>Then:</p> <div class="math-container">\[ v(X) = A\exp\left(\sqrt{\hat\lambda\frac{f_U^*-f_V^*}{f_U^*} }X\right)+B\exp\left(-\sqrt{\hat\lambda\frac{f_U^*-f_V^*}{f_U^*} }X\right) \]</div> <p>in the fast coordinate \(\xi= X/\epsilon^2\), we then get on the left:</p> <div class="math-container">\[ v(\xi) = A\exp\left(\epsilon^2\sqrt{\hat\lambda\frac{f_U^*-f_V^*}{f_U^*} }\xi \right) \]</div>]]></content><author><name></name></author><summary type="html"><![CDATA[For the slow equations, we introduce \(X=\epsilon x\). Then the (superslow) equations become: \[ \begin{aligned} \epsilon^2 \hat\lambda u &amp; = \epsilon^4u_{XX}+[f_U^* +\epsilon^2f_{UU}^* U_1^*+\epsilon^2f_{UV}^* (K_1^*-U_0^*)]u \\ &amp; +[f_V^* +\epsilon^2f_{VU}^* U_1^*+\epsilon^2f_{VU}^* (K^*_1-U_0^*)]v+\mathcal O(\epsilon^4) \\ \epsilon^2 \hat\lambda v &amp; = \epsilon^2 v_{XX}+[-f_U^* -\epsilon^2f_{UU}^* U_1^*-\epsilon^2f_{UV}^* (K_1^*-U_0^*)]u \\ &amp; +[-f_V^* -\epsilon^2f_{VU}^* U_1^*-\epsilon^2f_{VU}^* (K^*_1-U_0^*)]v+\mathcal O(\epsilon^4) \\ \end{aligned} \] Everything is exponentially close to constant. Both equations give at leading order: \[ u=-\frac{f_V^*}{f_U^*}v \] Now we add the equations and find at the next order: \[ \begin{aligned} \hat\lambda u+\hat\lambda v &amp; =v_{XX} \end{aligned} \] Then: \[ \begin{aligned} \hat\lambda\frac{f_U^*-f_V^*}{f_U^*} v &amp; = v_{XX} \end{aligned} \] Then: \[ v(X) = A\exp\left(\sqrt{\hat\lambda\frac{f_U^*-f_V^*}{f_U^*} }X\right)+B\exp\left(-\sqrt{\hat\lambda\frac{f_U^*-f_V^*}{f_U^*} }X\right) \] in the fast coordinate \(\xi= X/\epsilon^2\), we then get on the left: \[ v(\xi) = A\exp\left(\epsilon^2\sqrt{\hat\lambda\frac{f_U^*-f_V^*}{f_U^*} }\xi \right) \]]]></summary></entry><entry><title type="html">Homoclinics</title><link href="https://leanderhb.github.io/update/2024/homoclinics/" rel="alternate" type="text/html" title="Homoclinics"/><published>2024-09-18T00:00:00+00:00</published><updated>2024-09-18T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/homoclinics</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/homoclinics/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>We start by slightly shifting \(K\) and end up with \(K+\delta\) with \(\delta\ll 1\). Then we find the corrections to \(U^\pm_{het},V^\pm_{het}\) as:</p> <div class="math-container">\[\begin{aligned} U^\pm_{hom}=U^{\pm}_{het}+\delta \frac{f_V}{f_U}(U^\pm_{het},V^\pm_{het})\\ V^\pm_{hom}=V^\pm_{het}+\delta \end{aligned}\]</div> <p>Then the homoclinic Hamiltonian can be approximated (now for positive?? \(\delta\)):</p> <div class="math-container">\[ H_{hom}(U)=\int_{U^-_{hom}}^Uf(W, K+\delta-\epsilon^2 W)dW \]</div> <p>Assuming for now that \(\delta\ll \epsilon\), we can partially expand:</p> <div class="math-container">\[ H_{hom}(U)=\int_{U^{-}_{het}+\delta \frac{f_V^-}{f_U^-}}^Uf(W, K-\epsilon^2 W)+\delta f_V(W,K-\epsilon^2 W)dW \]</div> <p>Which we can reduce to:</p> <div class="math-container">\[\begin{aligned} H_{hom}(U)=H_{het}(U)+\int_{U^{-}_{het}+\delta \frac{f_V^-}{f_U^-}}^{U^{-}_{het}}f(W, K-\epsilon^2 W)dW\\ +\delta \int_{U_{het}^-}^U f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2) \end{aligned}\]</div> <p>but \(f\) is close to zero, and will at most get to order \(\delta\) as long as it stays \(O(\delta)\) from \(U_{het}^-\), so also this term can be neglected. So we’re left with:</p> <div class="math-container">\[ \begin{aligned} H_{hom}(U,\delta)=H_{het}(U)+\delta \int_{U_{het}^-}^U f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2) \end{aligned} \]</div> <p>Now by similar argument we find that:</p> <div class="math-container">\[ \begin{aligned} H_{hom}(U^+_{hom},\delta)&amp;=H_{het}(U^+_{hom})+\delta \int_{U_{het}^-}^{U^+_{hom}} f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2)\\ &amp;=\delta \int_{U_{het}^-}^{U^+_{het}} f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2) \end{aligned} \]</div> <p>Cool, now we can estimate how far away the turning point of the homoclinic orbit is, by using a quadratic approximation of \(H\) around \(U^+_{hom}\). We find:</p> <div class="math-container">\[ H(U+\mu) = H(U)+\mu H_U(U)+\mu^2/2 H_{UU}(U) \]</div> <p>We know the value of \(H(U)\) by above analysis, and know that \(H_U\) there is zero (top of the peak), and we know that \(H_{UU}=\partial_U f(U,K+\delta-\epsilon^2 U)\). So a leading order approximation of it is given by:</p> <div class="math-container">\[ H_{UU}=f_U(U^+_{het},V^+_{het}) \]</div> <p>So then:</p> <div class="math-container">\[ H(U+\mu_0)=0\implies \mu_0 = \pm\sqrt{2\delta \frac{1}{f_U^+}\int_{U_{het}^-}^{U^+_{het}} f_V(W,K-\epsilon^2 W)dW }+\mathcal O(\delta) \]</div> <p>let’s connect this to the rest of the theory to get an estimate of the width of the front:</p> <div class="math-container">\[ \epsilon^2 U_{xx}=f_U^+U \]</div> <p>is the equation close to the turning point. Then we solve it and find:</p> <div class="math-container">\[ U(x) = A\exp\left(\frac{\sqrt c}{\epsilon}x\right)+B\exp\left(-\frac{\sqrt c}{\epsilon}x\right) \]</div> <p>Solving for the initial conditions, we use \(U(0)=\mu_0,U_x(0)=0\) and get:</p> <div class="math-container">\[ U(x) = \frac{\mu_0}{2}\left(\exp\left(\frac{\sqrt c}{\epsilon}x\right)+\exp\left(-\frac{\sqrt c}{\epsilon}x\right)\right) \]</div> <p>but the expression in brackets is actually a known quantity: the cosh.</p> <div class="math-container">\[ U(x) = \mu_0\cosh\left(\frac{\sqrt c}{\epsilon}x\right) \]</div> <p>Let’s find when \(U(x)\) becomes order 1:</p> <div class="math-container">\[ \frac1{\mu_0} = \cosh\left(\frac{\sqrt c}{\epsilon}x\right) \]</div> <p>Solving for \(x\):</p> <div class="math-container">\[ x=\frac{\epsilon}{\sqrt c}\cosh^{-1}\left(\frac1{\mu_0}\right) \]</div> <p>Since \(\mu_0\ll 1\), we can approximate this by:</p> <div class="math-container">\[ x=\frac{\epsilon}{\sqrt c}\ln\left(\frac2{\mu_0}\right) \]</div> <p>Expanding the \(\ln\):</p> <div class="math-container">\[ x=\frac{\epsilon}{\sqrt c}\left(\ln 2-\ln\mu_0\right) \]</div> <p>Of course, we know that \(\ln 2\ll\ln\mu_0\), so to leading order, we get for the width:</p> <div class="math-container">\[ W=-\frac{2\epsilon}{\sqrt c}\ln\mu_0 \]</div> <p>again tossing away non-leading terms, we then also get:</p> <div class="math-container">\[ W=-\frac{2\epsilon}{\sqrt c}\ln{\sqrt\delta}=-\frac{\epsilon}{\sqrt c}\ln{\delta} \]</div> <p>So then:</p> <div class="math-container">\[ \delta = \exp\left(-\frac{\sqrt c}{\epsilon }W \right) \]</div>]]></content><author><name></name></author><summary type="html"><![CDATA[We start by slightly shifting \(K\) and end up with \(K+\delta\) with \(\delta\ll 1\). Then we find the corrections to \(U^\pm_{het},V^\pm_{het}\) as: \[\begin{aligned} U^\pm_{hom}=U^{\pm}_{het}+\delta \frac{f_V}{f_U}(U^\pm_{het},V^\pm_{het})\\ V^\pm_{hom}=V^\pm_{het}+\delta \end{aligned}\] Then the homoclinic Hamiltonian can be approximated (now for positive?? \(\delta\)): \[ H_{hom}(U)=\int_{U^-_{hom}}^Uf(W, K+\delta-\epsilon^2 W)dW \] Assuming for now that \(\delta\ll \epsilon\), we can partially expand: \[ H_{hom}(U)=\int_{U^{-}_{het}+\delta \frac{f_V^-}{f_U^-}}^Uf(W, K-\epsilon^2 W)+\delta f_V(W,K-\epsilon^2 W)dW \] Which we can reduce to: \[\begin{aligned} H_{hom}(U)=H_{het}(U)+\int_{U^{-}_{het}+\delta \frac{f_V^-}{f_U^-}}^{U^{-}_{het}}f(W, K-\epsilon^2 W)dW\\ +\delta \int_{U_{het}^-}^U f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2) \end{aligned}\] but \(f\) is close to zero, and will at most get to order \(\delta\) as long as it stays \(O(\delta)\) from \(U_{het}^-\), so also this term can be neglected. So we’re left with: \[ \begin{aligned} H_{hom}(U,\delta)=H_{het}(U)+\delta \int_{U_{het}^-}^U f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2) \end{aligned} \] Now by similar argument we find that: \[ \begin{aligned} H_{hom}(U^+_{hom},\delta)&amp;=H_{het}(U^+_{hom})+\delta \int_{U_{het}^-}^{U^+_{hom}} f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2)\\ &amp;=\delta \int_{U_{het}^-}^{U^+_{het}} f_V(W,K-\epsilon^2 W)dW +\mathcal O(\delta^2) \end{aligned} \] Cool, now we can estimate how far away the turning point of the homoclinic orbit is, by using a quadratic approximation of \(H\) around \(U^+_{hom}\). We find: \[ H(U+\mu) = H(U)+\mu H_U(U)+\mu^2/2 H_{UU}(U) \] We know the value of \(H(U)\) by above analysis, and know that \(H_U\) there is zero (top of the peak), and we know that \(H_{UU}=\partial_U f(U,K+\delta-\epsilon^2 U)\). So a leading order approximation of it is given by: \[ H_{UU}=f_U(U^+_{het},V^+_{het}) \] So then: \[ H(U+\mu_0)=0\implies \mu_0 = \pm\sqrt{2\delta \frac{1}{f_U^+}\int_{U_{het}^-}^{U^+_{het}} f_V(W,K-\epsilon^2 W)dW }+\mathcal O(\delta) \] let’s connect this to the rest of the theory to get an estimate of the width of the front: \[ \epsilon^2 U_{xx}=f_U^+U \] is the equation close to the turning point. Then we solve it and find: \[ U(x) = A\exp\left(\frac{\sqrt c}{\epsilon}x\right)+B\exp\left(-\frac{\sqrt c}{\epsilon}x\right) \] Solving for the initial conditions, we use \(U(0)=\mu_0,U_x(0)=0\) and get: \[ U(x) = \frac{\mu_0}{2}\left(\exp\left(\frac{\sqrt c}{\epsilon}x\right)+\exp\left(-\frac{\sqrt c}{\epsilon}x\right)\right) \] but the expression in brackets is actually a known quantity: the cosh. \[ U(x) = \mu_0\cosh\left(\frac{\sqrt c}{\epsilon}x\right) \] Let’s find when \(U(x)\) becomes order 1: \[ \frac1{\mu_0} = \cosh\left(\frac{\sqrt c}{\epsilon}x\right) \] Solving for \(x\): \[ x=\frac{\epsilon}{\sqrt c}\cosh^{-1}\left(\frac1{\mu_0}\right) \] Since \(\mu_0\ll 1\), we can approximate this by: \[ x=\frac{\epsilon}{\sqrt c}\ln\left(\frac2{\mu_0}\right) \] Expanding the \(\ln\): \[ x=\frac{\epsilon}{\sqrt c}\left(\ln 2-\ln\mu_0\right) \] Of course, we know that \(\ln 2\ll\ln\mu_0\), so to leading order, we get for the width: \[ W=-\frac{2\epsilon}{\sqrt c}\ln\mu_0 \] again tossing away non-leading terms, we then also get: \[ W=-\frac{2\epsilon}{\sqrt c}\ln{\sqrt\delta}=-\frac{\epsilon}{\sqrt c}\ln{\delta} \] So then: \[ \delta = \exp\left(-\frac{\sqrt c}{\epsilon }W \right) \]]]></summary></entry><entry><title type="html">Thesis handige thms</title><link href="https://leanderhb.github.io/update/2024/thesis-handige-thms/" rel="alternate" type="text/html" title="Thesis handige thms"/><published>2024-09-18T00:00:00+00:00</published><updated>2024-09-18T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/thesis-handige-thms</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/thesis-handige-thms/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <h1 id="thms">thms</h1> <p><img src="/assets/images/Pasted image 20240215153011.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240215153011.png"/> (Abel’s Thm?) <img src="/assets/images/Pasted image 20240215155740.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240215155740.png"/></p> <p>Homogeneous sols: <img src="/assets/images/Pasted image 20240215160407.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240215160407.png"/></p> <p><img src="/assets/images/Pasted image 20240216164924.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240216164924.png"/></p> <p>essential spectrum ligt op negative real part: <img src="/assets/images/Pasted image 20240216165812.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240216165812.png"/>vul in dat \(a_0^\pm\) de slopes zijn van de intersection reactive NC en flux-balance lijn!</p> <p><img src="/assets/images/Pasted image 20240216180438.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240216180438.png"/></p> <p><img src="/assets/images/Pasted image 20240216180512.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240216180512.png"/> lol al het werk eerder in 1 slide</p> <p><img src="/assets/images/Pasted image 20240221151840.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240221151840.png"/> <img src="/assets/images/Pasted image 20240221152222.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240221152222.png"/></p> <p><img src="/assets/images/Pasted image 20240221152707.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240221152707.png"/></p> <p>Boundary layer thickness: <img src="/assets/images/Pasted image 20240227160002.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240227160002.png"/>Dus dat geeft een estimate op hoe dik we die willen hebben.</p> <div class="math-container">\[ d \sim \sqrt\delta \]</div> <p><img src="/assets/images/Pasted image 20240311125859.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240311125859.png"/></p> <p>niet bewezen?? <img src="/assets/images/Pasted image 20240312153150.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240312153150.png"/></p> <p>Dit is ongeveer wat ik deed met mn staarten? <img src="/assets/images/Pasted image 20240315141901.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240315141901.png"/></p> <p>laten zien dat snelheid \(\epsilon^2\): <img src="/assets/images/Pasted image 20240326171327.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240326171327.png"/></p> <p>waarom BL? <img src="/assets/images/Pasted image 20240409113124.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240409113124.png"/></p> <p><img src="/assets/images/Pasted image 20240603143347.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240603143347.png"/></p> <p><img src="/assets/images/Pasted image 20240909153206.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240909153206.png"/></p> <p>arjens notes <img src="/assets/images/Pasted image 20240912185201.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240912185201.png"/></p> <p><img src="/assets/images/Pasted image 20240918134916.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240918134916.png"/></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry></feed>