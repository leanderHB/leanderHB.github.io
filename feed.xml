<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://leanderhb.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://leanderhb.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-10-02T22:08:01+00:00</updated><id>https://leanderhb.github.io/feed.xml</id><title type="html">blank</title><subtitle>Pagina voor Leander Post, bevat thesis en wat ander werk. </subtitle><entry><title type="html">DV_JDDE</title><link href="https://leanderhb.github.io/update/2024/dv_jdde/" rel="alternate" type="text/html" title="DV_JDDE"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/dv_jdde</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/dv_jdde/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>Lemma 3.2 Let \(H: \mathbb{R}_{\geq 0} \rightarrow \mathbb{R}\) be such that the differential equation \(w_{x x}=\rho w-\) \(H(w), \rho&gt;0\) has a solution \(w_h\) which is homoclinic to \(\left(w, w_x\right)=(0,0)\), and write \(h(x)=H^{\prime}\left(w_h(x)\right)\). For a differential operator of the form \(\mathcal{L}(x)=\frac{d^2}{d x^2}+h(x)-\rho\), consider the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\) with boundary conditions \(\lim _{x \rightarrow \pm \infty} w(x)=0\). Moreover, define \(\Lambda=\sqrt{\rho+\lambda} ; \arg (\Lambda) \in\left(-\frac{\pi}{2}, \frac{\pi}{2}\right]\). Then the following holds: (i) There is a finite number of real eigenvalues \(\lambda_j, j=0,1, \cdots, J\) for <del>which \(\lambda_0&gt;0, \lambda_1=\) 0 and \(0&gt;\lambda_2&gt;\cdots&gt;\lambda_J&gt;-\rho\). ~~Equivalently, there is a finite number of real eigenvalues \(\Lambda_j\) for which \(\Lambda_0&gt;\sqrt{\rho}, \Lambda_1=\sqrt{\rho}\) and \(\sqrt{\rho}&gt;\Lambda_2&gt;\cdots&gt;\Lambda_J&gt;0\). (ii) The associated eigenfunctions \(w_j(x)\) have \(j\) distinct zeroes and are ~~even resp. odd as a function of \(x\) if \(j\) is even resp. odd.</del> Moreover, \(\frac{d}{d x} w_h(x)\) is an eigenfunction for \(\lambda_1=0\) \(\left(\right.\) or \(\left.\Lambda_1=1\right)\); in other words, \(w_1(x) \in \operatorname{span}\left\{\frac{d}{d x} w_h(x)\right\}\). (iii) The eigenfunctions \(w_j(x), j=0, \cdots, J\) form an orthogonal set:</p> <div class="math-container">\[ \left\langle w_j, w_k\right\rangle=\int_{-\infty}^{\infty} w_j(x) w_k(x) d x=0 \text { for } j \neq k \text {, and }\left\|w_j\right\|_2=\sqrt{\left\langle w_j, w_j\right\rangle} \neq 0 ; \]</div> <p>these eigenfunctions can be determined uniquely by the condition</p> <div class="math-container">\[ w_j(x) \sim 1 \cdot e^{-\Lambda_j x} \text { as } x \rightarrow \infty \]</div> <p>(iv) The spectrum associated to the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\) is given by \(\sigma_\lambda=(-\infty,-\rho) \cup\left\{\lambda_0, \cdots, \lambda_J\right\}\) or equivalently \(\sigma_{\Lambda}=i \mathbb{R}_{&gt;0} \cup\left\{\Lambda_0, \cdots, \Lambda_J\right\}\). (v) For every \(\lambda \notin \sigma_\lambda\), there is a unique solution \(w_\lambda^{\mathrm{R}}(x)\) (which depends smoothly on \(\lambda\) ) such that</p> <div class="math-container">\[ w_\lambda^{\mathrm{R}}(x) \sim 1 \cdot e^{-\Lambda x} \text { as } x \rightarrow \infty . \]</div> <p>Moreover, the pair \(\left\{w_\lambda^{\mathrm{R}}, w_\lambda^{\mathrm{L}}\right\}\) with \(w_\lambda^{\mathrm{L}}(x)=w_\lambda^{\mathrm{R}}(-x)\) spans the solution space of the eigenvalue problem \([\mathcal{L}(x)-\lambda] w=0\).</p> <p>For (3.12) we can apply the above lemma with \(\rho=1\), obtaining a set of fast eigenvalues \(\lambda_{f, j}\) and their associated eigenfunctions \(w_{f, j}(\xi)\). Moreover, we observe that for \(\rho=1, \Lambda=\Lambda_f\) \((3.8)\). Next, we consider the Wronskian</p> <div class="math-container">\[ \mathcal{W}(\lambda) \stackrel{\text { def }}{=} \operatorname{det}\left(\begin{array}{cc} w_\lambda^{\mathrm{L}}(\xi) &amp; w_\lambda^{\mathrm{R}}(\xi) \\ \frac{d}{d \xi} w_\lambda^{\mathrm{L}}(\xi) &amp; \frac{d}{d \xi} w_\lambda^{\mathrm{R}}(\xi) \end{array}\right) \]</div> <p>associated to (3.12). For notational convenience we only consider \(\mathcal{W}\) as function of \(\lambda\) here and in the upcoming lemma. In the forthcoming analysis we will however often switch between the equivalent expressions \(\mathcal{W}(\lambda)\) and \(\mathcal{W}\left(\Lambda_f\right)\). This Wronskian can be defined as a smooth, in fact analytic, function of \(\lambda\) for all \(\lambda \in \mathbb{C}\) outside the (closure of the) essential spectrum associated to (3.12), i.e. for \(\lambda \notin(-\infty,-1]\), but including the (eigen)values \(\lambda=\lambda_{f, j}\) (Lemma 3.2), by setting \(\mathcal{W}\left(\lambda_{f, j}\right)=0, j=0, \ldots, J\) [33]. Note that \(\mathcal{W}(\lambda)\) is in fact an Evans function [1]. In combination with Lemma 3.2, the following result on \(\mathcal{W}(\lambda)\) enables us to generalize the GS/GM-type hypergeometric functions approach to the present setting.</p> <p>Lemma 3.3 Let \(\mathcal{W}(\lambda)\) be the Wronskian associated to (3.12) and let \(\lambda \notin(-\infty,-1]\), then</p> <div class="math-container">\[ \mathcal{W}(\lambda) \sim(-1)^{j+1}\left\|w_{f, j}\right\|_2^2\left(\lambda-\lambda_{f, j}\right) \quad \text { as } \quad \lambda \rightarrow \lambda_{f, j}, j=0, \ldots, J . \]</div> <p>See Fig. 5 for a sketch of a \(\mathcal{W}(\lambda)\) for real \(\lambda&gt;-1\). Proof Since we know that \(\mathcal{W}(\lambda)\) is a smooth function of \(\lambda\) near its zeroes \(\lambda_{f, j}\), the proof can be based on a (finite) Taylor expansion of \(\mathcal{W}\left(\lambda_{f, j}+\delta\right)\) for \(\delta=\lambda-\lambda_{f, j} \in \mathbb{C}\) small. To do so, we first need to approximate \(w_\lambda^{\mathrm{R}}(\xi)\) for \(\lambda=\lambda_{f, j}+\delta\). Therefore, we introduce the (regular) approximation</p> <div class="math-container">\[ w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)=w_{f, j}(\xi)+\delta w_{1, j}(\xi)+\mathcal{R}(\xi ; \delta), \]</div> <p>in which \(\mathcal{R}(\xi ; \delta)\) represents the error terms. This expansion can in general not give a valid approximation of \(w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)\) for \(\xi \rightarrow \infty\). However, it follows directly from Poincaré’s expansion theorem (see for instance [39]) that for every \(\rho \in[0,1)\) there is a positive \(\mathcal{O}(1)\) constant \(C_\rho\) such that</p> <div class="math-container">\[ \left|w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)-\left(w_{f, j}(\xi)+\delta w_{1, j}(\xi)\right)\right|=|\mathcal{R}(\xi ; \delta)|&lt;C_\rho \delta^{2(1-\rho)}, \]</div> <p>for \(|\xi|&lt;\mathcal{O}\left(\delta^{-\rho}\right)\). Note that the standard (and natural) result that \(\mathcal{R}(\xi ; \delta) \mid=\mathcal{O}\left(\delta^2\right)\) on \(\mathcal{O}(1) \xi\)-intervals corresponds to the case \(\rho=0\) in (3.17). To determine the leading order correction \(w_{1, j}(\xi)\), we substitute (3.16) into (3.12) and obtain the inhomogeneous problem</p> <div class="math-container">\[ \left(\mathcal{L}_f(\xi)-\lambda_{f, j}\right) w_{1, j}=w_{f, j}(\xi)+\mathcal{O}\left(\delta^{1-2 \rho}\right) \]</div> <p>(3.12) on the domain \(|\xi|&lt;\mathcal{O}\left(\delta^{-\rho}\right)\). It is clear that for the above to be a leading order expression, \(\rho&lt;\frac{1}{2}\) must hold. This equation cannot have a solution that is bounded on \(\mathbb{R}\), since the operator \(\mathcal{L}_f(\xi)-\lambda\) is not invertible at \(\lambda=\lambda_{f, j}\) and the inhomogeneous term \(b(\xi)=w_{f, j}(\xi)\) clearly does not satisfy the solvability condition \(\left\langle b, w_{f, j}\right\rangle=\left\langle w_{f, j}, w_{f, j}\right\rangle=\) 0 , see also Sect. 3.3. However, this is not a problem: we are constructing an approximation of a solution \(w_\lambda^{\mathrm{R}}(\xi)\) and this solution need not be bounded on \(\mathbb{R}\) for \(\lambda \neq \lambda_{f, j}\) (Lemma 3.2). Since \(w_{f, j}(\xi)\) is a solution of the homogeneous problem, we apply the variation of constants method, i.e. we introduce the unknown function \(c_j(\xi)\) by \(w_{1, j}(\xi)=c_j(\xi) w_{f, j}(\xi)\) and obtain an equation for \(c_j\) :</p> <div class="math-container">\[ \ddot{c}_j w_{f, j}+2 \dot{c}_j \dot{w}_{f, j}=w_{f, j} \]</div> <p>This implies that</p> <div class="math-container">\[ \dot{c}_j(\xi)=\frac{1}{w_{f, j}^2(\xi)}\left[\int_0^{\xi} w_{f, j}^2(\eta) d \eta+c_{1, j}\right], \]</div> <p>where \(c_{1, j}\) is a constant of integration. Writing \(c_{1, j}=\hat{c}_{1, j}-\int_0^{\infty} w_{f, j}^2(\eta) d \eta\), we investigate the behaviour of \(\dot{c}_j(\xi)\) as \(\xi \rightarrow \delta^{-\rho}\). From Lemma 3.2, we know that \(w_{f, j}(\xi) \sim e^{-\Lambda_{f, j} \delta^{-\rho}}\) as \(\xi \rightarrow \delta^{-\rho}\). Therefore,</p> <div class="math-container">\[ \begin{aligned} \dot{c}_j(\xi) \sim &amp; e^{2 \Lambda_{f, j} \delta^{-\rho}}\left[\int_0^{\delta^{-\rho}} w_{f, j}^2(\eta) d \eta-\int_0^{\infty} w_{f, j}^2(\eta) d \eta+\hat{c}_{1, j}\right] \\ &amp; =\left[-\int_{\delta^{-\rho}}^{\infty} w_{f, j}^2(\eta) d \eta+\hat{c}_{1, j}\right] e^{2 \Lambda_{f, j} \delta^{-\rho}} \\ &amp; =-\frac{1}{2 \Lambda_{f, j}}+\hat{c}_{1, j} e^{2 \Lambda_{f, j} \delta^{-\rho}} \end{aligned} \]</div> <p>as \(\xi \rightarrow \delta^{-\rho}\). Since the solution \(w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)\) (3.16) does not grow exponentially as \(\xi \rightarrow \delta^{-\rho}\) (3.14), it necessarily follows that \(w_{1, j}(\xi)\) does neither. Therefore, \(c_j(\xi)\) can at most grow as \(\frac{1}{w_{f, j}}\), which is as \(e^{\Lambda_{f, j} \xi}\). From this, it follows that \(\hat{c}_{1, j}=0\) and therefore</p> <div class="math-container">\[ c_{1, j}=-\int_0^{\infty} w_{f, j}^2(\eta) d \eta \quad \text { so that } \dot{c}_j(\xi)=-\frac{1}{w_{f, j}^2(\xi)} \int_{\xi}^{\infty} w_{f, j}^2(\eta) d \eta . \]</div> <p>We now return to the Wronskian (3.15). Since \(w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi)=w_{f, j}(\xi)\left(1+\delta c_j(\xi)\right)+\mathcal{R}(\xi ; \delta)\), we can use Lemma 3.2 (ii),(v) to obtain</p> <div class="math-container">\[ \begin{aligned} w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi) &amp; =w_{f, j}(\xi)\left(1+\delta c_j(\xi)\right)+\mathcal{R}(\xi ; \delta) \\ w_{\lambda_{f, j}+\delta}^{\mathrm{L}}(\xi) &amp; =(-1)^j w_{f, j}(\xi)\left(1+\delta c_j(-\xi)\right)+\mathcal{R}(-\xi ; \delta) \\ \frac{\mathrm{d}}{\mathrm{d} \xi} w_{\lambda_{f, j}+\delta}^{\mathrm{R}}(\xi) &amp; =\frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi}(\xi)\left(1+\delta c_j(\xi)\right)+\delta w_{f, j}(\xi) \frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}(\xi ; \delta) \\ \frac{\mathrm{d}}{\mathrm{d} \xi} w_{\lambda_{f, j}+\delta}^{\mathrm{L}}(\xi) &amp; =(-1)^j\left[\frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi}(\xi)\left(1+\delta c_j(-\xi)\right)-\delta w_{f, j}(\xi) \frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right]-\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}(-\xi ; \delta) \end{aligned} \]</div> <p>Since \(w_\lambda^{\mathrm{L} / \mathrm{R}}(\xi)\) depends smoothly on \(\lambda\) (cf. Lemma 3.2), the Poincaré expansion theorem can be applied to \(\frac{\mathrm{d}}{\mathrm{d} \xi} w_{\lambda_{f, j}+\delta}^{\mathrm{R}}\) to obtain the result that for every \(\hat{\rho} \in[0,1)\) there is a \(C_{\hat{\rho}}\) such that \(\left|\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}(\xi ; \delta)\right|&lt;C_{\hat{\rho}} \delta^{2(1-\hat{\rho})}\). Choosing \(\hat{\rho}=\rho&lt;\frac{1}{2}\) enables us to treat \(\frac{\mathrm{d} \mathcal{R}}{\mathrm{d} \xi}\) as a higher order term. Using the above expansions for the Wronskian, we obtain</p> <div class="math-container">\[ \begin{aligned} \mathcal{W}\left(\lambda_{f, j}+\delta\right)= &amp; (-1)^j\left(w_{f, j} \frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi}-\frac{\mathrm{d} w_{f, j}}{\mathrm{~d} \xi} w_{f, j}\right)\left(1+\delta c_j(\xi)+\delta c_j(-\xi)\right) \\ &amp; +\delta(-1)^j w_{f, j}^2(\xi)\left[\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right]+\mathcal{O}\left(\delta^2\right) \\ = &amp; \delta(-1)^j w_{f, j}^2(\xi)\left[\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right]+\mathcal{O}\left(\delta^2\right), \end{aligned} \]</div> <p>in which we refrained from explicitly writing down all \(\mathcal{O}\left(\delta^2\right)=\mathcal{O}\left(\left|\lambda-\lambda_{f, j}\right|^2\right)\) correction terms. Using (3.19), we see that</p> <div class="math-container">\[ \begin{aligned} w_{f, j}^2(\xi)\left[\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(\xi)+\frac{\mathrm{d} c_j}{\mathrm{~d} \xi}(-\xi)\right] &amp; =-\int_{\xi}^{\infty} w_{f, j}^2(\eta) \mathrm{d} \eta-\int_{-\xi}^{\infty} w_{f, j}^2(\eta) \mathrm{d} \eta=-\int_{-\infty}^{\infty} w_{f, j}^2(\eta) \mathrm{d} \eta \\ &amp; =-\left\|w_{f, j}\right\|_2^2 \end{aligned} \]</div> <p>using again Lemma 3.2 (ii).</p> <p>Clearly, the Wronskian \(\mathcal{W}(\lambda)\) has an extremum for \(\lambda \in \mathbb{R}\) between two successive eigenvalues. Based on the previous lemma it can easily be established that this extremum is a maximum between \(\lambda_{2 j+1}&lt;\lambda_{2 j}\) and a minimum between \(\lambda_{2 j}&lt;\lambda_{2 j-1}\). The following lemma determines the limit behavior of \(\mathcal{W}(\lambda)\) for \(\lambda \in \mathbb{R}\) large, see also Fig. 5.</p> <p>Lemma 3.4 Let \(\mathcal{W}(\lambda)\) be the Wronskian associated to (3.12) and let \(\lambda \in \mathbb{R} \backslash(-\infty,-1]\), then</p> <div class="math-container">\[ \mathcal{W}(\lambda) \leadsto-2 \sqrt{\lambda} \text { as } \lambda \rightarrow+\infty . \]</div> <p>Proof Define \(\delta=1 / \Lambda_f&gt;0\left(\Lambda_f \in \mathbb{R}\right)\). It can be shown by the methods of the above proof that for \(\delta\) small enough, i.e. \(\Lambda_f&gt;0\) large enough,</p> <div class="math-container">\[ w_\lambda^{\mathrm{R}}(\xi)=e^{-\Lambda_f \xi}(1+\mathcal{O}(\delta)), \quad \text { and } \quad w_\lambda^{\mathrm{L}}(\xi)=e^{\Lambda_f \xi}(1+\mathcal{O}(\delta)) . \]</div> <p>on an \(\mathcal{O}(1) \xi\)-domain \(\supset\{\xi=0\}\). Hence, for \(\Lambda_f\) large enough,</p> <div class="math-container">\[ \begin{aligned} \mathcal{W}\left(\Lambda_f\right) &amp; =\operatorname{det}\left(\begin{array}{cc} e^{\Lambda_f \xi}(1+\mathcal{O}(\delta)) &amp; e^{-\Lambda_f \xi}(1+\mathcal{O}(\delta)) \\ \Lambda_f e^{\Lambda_f \xi}(1+\mathcal{O}(\delta)) &amp; -\Lambda_f e^{-\Lambda_f \xi}(1+\mathcal{O}(\delta)) \end{array}\right) \\ &amp; =-2 \Lambda_f(1+\mathcal{O}(\delta)) \end{aligned} \]</div> <p>which is equivalent to the statement of the lemma by the definition of \(\Lambda_f\) (3.8). 3.3 The Inhomogeneous Fast Reduced Sturm-Liouville Problem</p> <p>Since the inhomogeneous problem (3.11) is linear (and can thus be rescaled), we define \(v_{\text {in }}(\xi ; \lambda)\) as the bounded solution of</p> <div class="math-container">\[ \left(\mathcal{L}_f(\xi)-\lambda\right) v=-\frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\xi ; u_*\right)\right) . \]</div> <p>Note that this is only possible if \(u(0) \neq 0\); the situation where \(u(0)=0\) will be treated in Sect. 5 (which is related to the case \(B_{-}(\lambda)=0\) there). It follows from the general theory on Sturm-Liouville problems that \(v_{\text {in }}(\xi ; \lambda)\) is uniquely determined for \(\lambda \notin \sigma_f\) ([33]). Since \(\left\{w_\lambda^{\mathrm{L}}(\xi), w_\lambda^{\mathrm{R}}(\xi)\right\}=\left\{w_\lambda^{\mathrm{R}}(-\xi), w_\lambda^{\mathrm{R}}(\xi)\right\}\) span the solution space associated to the homogeneous problem (Lemma 3.2), \(v_{\text {in }}(\xi ; \lambda)\) can be determined explicitly (in terms of \(\left.w_\lambda^{\mathrm{R}}( \pm \xi)\right)\).</p> <p>Lemma 3.5 The bounded solution of (3.25) is given by \(v_{i n}(\xi ; \lambda)=A(\xi) w_\lambda^{\mathrm{R}}(\xi)+\) \(A(-\xi) w_\lambda^{\mathrm{R}}(-\xi)\), with</p> <div class="math-container">\[ A(\xi)=A(\xi ; \lambda)=-\frac{1}{\mathcal{W}(\lambda)} \int_{-\infty}^{\xi} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_\lambda^{\mathrm{R}}(-\tilde{\xi}) d \tilde{\xi} \]</div> <p>Note that it immediately follows from this expression and assumption (A4) in combination with the properties of \(v_{f, h}\left(\xi ; u_*\right)\) that \(v_{\text {in }}(\xi ; \lambda)\) decays exponentially fast to 0 as \(\xi \rightarrow \pm \infty\) (and as \(\xi\) approaches the boundaries of \(I_f(2.7)\) ).</p> <p>Proof By the variation of constants approach, we introduce the unknown functions \(A^{\mathrm{L} / \mathrm{R}}(\xi)\) by \(v_{\text {in }}(\xi)=A^{\mathrm{L}}(\xi) w_\lambda^{\mathrm{L}}(\xi)+A^{\mathrm{R}}(\xi) w_\lambda^{\mathrm{R}}(\xi)\). Substitution in (3.25) yields</p> <div class="math-container">\[ \dot{A}^{\mathrm{L} / \mathrm{R}}=\frac{\mp 1}{\mathcal{W}(\lambda)} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\xi ; u_*\right)\right) w_\lambda^{\mp}(\xi) \]</div> <p>so that</p> <div class="math-container">\[ A^{\mathrm{L} / \mathrm{R}}(\xi)=A^{\mathrm{L} / \mathrm{R}}(0) \mp \frac{1}{\mathcal{W}(\lambda)} \int_0^{\xi} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_\lambda^{\mp}(\tilde{\xi}) d \tilde{\xi} . \]</div> <p>Both the operator \(\mathcal{L}_f(\xi)\) and the inhomogeneous term in (3.25) are even as function of \(\xi\). This implies that also \(v_{\text {in }}(\xi ; \lambda)\) must be even, so that \(A^{\mathrm{R}}(\xi)=A^{\mathrm{L}}(-\xi) \stackrel{\text { def }}{=} A(\xi)\) and \(A^{\mathrm{R}}(0)=A^{\mathrm{L}}(0)\). A straightforward analysis yields that \(v_{\text {in }}(\xi)\) can only be bounded if</p> <div class="math-container">\[ A(0)=-\frac{1}{\mathcal{W}(\lambda)} \int_{-\infty}^0 \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_\lambda^{\mathrm{L}}(\tilde{\xi}) d \tilde{\xi} \]</div> <p>which is a converging integral by assumption (A4). A priori, there is a singularity in the solutions \(v_{\text {in }}(\xi ; \lambda)\) as \(\lambda \rightarrow \lambda_{f, j}\), due to the fact that \(\left(\mathcal{L}_f(\xi)-\lambda\right)\) is not invertible at \(\lambda_{f, j}\) (and that thus \(\mathcal{W}\left(\lambda_{f, j}\right)=0\), Lemma 3.3). However, by the Fredholm alternative, (3.25) will have solutions for \(\lambda=\lambda_{f, j}\) with \(j\) odd, since \(w_{f, j}(\xi)\) is odd as function of \(\xi\) (Lemma 3.2) and the (even) inhomogeneity of (3.25) thus satisfies the solvability condition.</p> <p>Corollary 3.6 For \(j\) even,</p> <div class="math-container">\[ v_{i n}(\xi ; \lambda) \sim\left(\frac{w_{f, j}(\xi)}{\left\|w_{f, j}\right\|_2^2} \int_{-\infty}^{\infty} \frac{\partial G}{\partial U}\left(u_*, v_{f, h}\left(\tilde{\xi} ; u_*\right)\right) w_{f, j}(\tilde{\xi}) d \tilde{\xi}\right) \cdot \frac{1}{\lambda-\lambda_{f, j}} \text { as } \lambda \rightarrow \lambda_{f, j}, \]</div> <p>while \(\lim _{\lambda \rightarrow \lambda_{f, j}} v_{i n}(\xi ; \lambda)\) exists for \(j\) odd. Proof Using the fact that \(w_{f, j}(\xi)\) is even/odd as function of \(\xi\) for \(j\) even/odd, identity (3.27) can be obtained directly by combining Lemmas 3.3 and 3.5, both for \(j\) even and for \(j\) odd—in the latter case, the integral in (3.27) vanishes.</p> <p>It will be necessary to also have an explicit characterization of \(v_{\text {in }}(\xi ; \lambda)\) for \(\lambda\) near \(\lambda_{f, 1}\), the crucial (odd) case \(j=1\) for which \(\lambda_{f, 1}=0\).</p> <p>Lemma 3.7 For \(\lambda=\lambda_{f, 1}=0, v_{\text {in }}(\xi ; \lambda)\) is not uniquely determined: here,</p> <div class="math-container">\[ v_{i n}(\xi ; 0)=\left.\frac{\partial}{\partial u} v_{f, h}(\xi ; u)\right|_{u=u_*}+C \dot{v}_{f, h}\left(\xi ; u_*\right) \]</div> <p>in which \(C \in \mathbb{R}\) is a free parameter. It is also possible to obtain leading order approximations of \(v_{\text {in }}(\xi ; \lambda)\) for \(\lambda\) near \(\lambda_{f, j}\) with \(j \geq 3\) odd. However, we refrain from going into these details.</p> <p>Proof The fact that</p> <div class="math-container">\[\left.\frac{\partial}{\partial u} v_{f, h}(\xi ; u)\right|_{u=u_*}\]</div> <p>is a solution of (3.25) follows immediately from taking the derivative with respect to the parameter \(u\) (or \(u_0\) ) in (2.3). Uniqueness is lost by adding the kernel \(\dot{v}_{f, h}\left(\xi ; u_*\right)\) associated to the operator \(\mathcal{L}_f(\xi)\).</p> <p><a href="/assets/md/DV_JDDE.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Grid based derivation</title><link href="https://leanderhb.github.io/update/2024/grid-based-derivation/" rel="alternate" type="text/html" title="Grid based derivation"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/grid-based-derivation</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/grid-based-derivation/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>If the plant is there and the food is there, there’s a certain probability of the plant uptaking the food. Also, plant have a certain chance of “duplicating”, by taking up the food. Besides that, the plants and the food do a random walk with a certain rate.</p> <ul> <li>plant eats food: \(P+F \xrightarrow{\alpha(P,F)} 2P\)</li> <li>plant dies: \(P\xrightarrow{\beta(P,F)} F\)</li> <li>plant hops: \(P_i \xrightarrow{d_P}P_{i\pm 1}\)</li> <li>food hops: \(F_i \xrightarrow{d_F}F_{i\pm 1}\) We do the classic thing of finding how the probability at a site changes:</li> </ul> <div class="math-container">\[\begin{aligned} \frac{dP_i}{dt} = \underbrace{d_P\left( P_{i-1}+P_{i+1} \right)}_{\text{hopping to i}}-\underbrace{2d_PP_i}_{\text{hopping away}}+\underbrace{\alpha(P,F)PF}_{\text{plant duplicates}}-\underbrace{\beta(P,F) P}_{\text{plant dies}}\\ \frac{dF_i}{dt} = \underbrace{d_F\left( F_{i-1}+F_{i+1} \right)}_{\text{hopping to i}}-\underbrace{2d_FF_i}_{\text{hopping away}}-\underbrace{\alpha(P,F)PF}_{\text{food eaten}}+\underbrace{\beta(P,F) P}_{\text{new food}} \end{aligned}\]</div> <p>Taking the continuum limit, we get:</p> <div class="math-container">\[\begin{aligned} P_t = D_P P_{xx}+\alpha(P,F)PF-\beta(P,F) P\\ F_t = D_F F_{xx}-\alpha(P,F)PF+\beta(P,F) P \end{aligned}\]</div> <p>More generally, with a bit of rescaling, we get:</p> <div class="math-container">\[\begin{aligned} U_t&amp;=D U_{xx}+f(U,V)\\ V_t &amp;=V_{xx}-f(U,V) \end{aligned}\]</div> <p>with \(f\) now a general function of \(U\) and \(V\), now some generalized concentrations.</p> <p>This is called a reaction diffusion system, with conserved concentration :)</p> <h1 id="slides-for-fourier">Slides for fourier</h1> <p>Integral should have a real value. Then the left hand side should be real too. Then for positive, real \(\lambda\), we require that the square roots be real. If they aren’t, we can’t have positive, real \(\lambda\), which is interesting. This implies:</p> <div class="math-container">\[ f_{V,r}&lt;f_{U,r},\quad f_{V,l}&lt;f_{U,l} \]</div> <p>is necessary for instability in the form of a real (non-oscillating) eigenvalue.</p> <p>Let’s check the stability around \((U_+,V_+)\). We linearize again:</p> <div class="math-container">\[ \begin{aligned} u_t &amp;= \epsilon^2 u_{xx}+f_U(U_+,V_+)u+f_V(U_+,V_+)v\\ v_t &amp;= v_{xx}-f_U(U_+,V_+)u-f_V(U_+,V_+)v \end{aligned} \]</div> <p>A quick Fourier transform (we assume we’re far away enough from any structure that we can do this, other words, the slow reduced system), shows us that:</p> <div class="math-container">\[\begin{aligned} \hat{u}_t = \epsilon^2(ik)^2\hat{u}+f_U \hat{u}+f_V\hat{v}\\ \hat{v}_t = (ik)^2\hat{v}-f_U\hat{u}-f_V\hat{v} \end{aligned} \]</div> <p>We now write this as:</p> <div class="math-container">\[ \begin{pmatrix}\hat{u}\\\hat{v}\end{pmatrix}_t= \begin{pmatrix}f_U-\epsilon^2k^2&amp;f_V\\-f_U&amp;-f_V-k^2\end{pmatrix} \begin{pmatrix}\hat{u}\\\hat{v}\end{pmatrix} \]</div> <p>Which has determinant:</p> <div class="math-container">\[\begin{aligned} \Delta\begin{pmatrix}f_U-\epsilon^2k^2&amp;f_V\\-f_U&amp;-f_V-k^2\end{pmatrix} &amp;=(f_U-\epsilon^2k^2)(-f_V-k^2)+f_Uf_V \\ &amp;= -f_Uk^2+\epsilon^2 k^2 f_V+ \epsilon^2k^4\\ &amp;= k^2(\epsilon^2 k^2+\epsilon^2 f_V-f_U) \end{aligned}\]</div> <p>We require the determinant to be positive for non-growing waves. We see that a bifurcation happens, if it does at all, for \(k=0\), since that makes the determinant closest to 0. Then we find that for stability of all wavenumbers, we need \(\epsilon^2 f_V-f_U&gt;0\). Next, we look at the trace, and find that</p> <div class="math-container">\[ \operatorname{Tr}\begin{pmatrix}f_U-\epsilon^2k^2&amp;f_V\\-f_U&amp;-f_V-k^2\end{pmatrix} =f_U-\epsilon^2k^2-f_V-k^2 \]</div> <p>For stability, we require \(\operatorname{Tr}&lt;0\), so here we get another inequality for stability:</p> <div class="math-container">\[ f_V-f_U&gt;0 \]</div> <p><a href="/assets/md/Grid based derivation.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Meeting tips</title><link href="https://leanderhb.github.io/update/2024/meeting-tips/" rel="alternate" type="text/html" title="Meeting tips"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/meeting-tips</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/meeting-tips/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <h3 id="arjen">arjen</h3> <p>dakje eraf: kleine letter</p> <p>pulsen: kleine mu op K, zodat vergelijken met wat we nu hebben,</p> <p>afgeleide naar mu: nieuwe eigenwaarde?</p> <h3 id="mazi">mazi</h3> <p>kpz</p> <p>simulate radial</p> <p><a href="/assets/md/Meeting tips.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Nu is twee!</title><link href="https://leanderhb.github.io/update/2024/nu-is-twee!/" rel="alternate" type="text/html" title="Nu is twee!"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/nu-is-twee!</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/nu-is-twee!/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <h2 id="nu-order-2-slow">Nu order 2 Slow</h2> <p>We now look at the slow system, where:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat u =\epsilon^2 \hat u_{xx}+f_u^*(u^*_0,K_0^*)\hat u+f_v^*(u^*_0,K_0^*)\hat v \\ \hat\lambda \epsilon^{2} \hat v = \hat v_{xx}- f_u^*(u^*_0,K_0^*)\hat u- f_v^*(u^*_0,K_0^*)\hat v \end{aligned} \]</div> <p>We find that: Well we require the orders to match so let’s substitute \(\hat u=\epsilon^2 \hat{\hat u}\) (why u?? I guess to match \(\hat v\)) and \(\hat v=\epsilon^2 \hat{\hat v}\). This doesn’t really change the equations much:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat{\hat u} =\epsilon^2 \hat{\hat u}_{xx}+f_u^*(u^*_0,K_0^*)\hat{\hat u}+f_v^*(u^*_0,K_0^*)\hat{\hat v} \\ \hat\lambda \epsilon^{2} \hat{\hat v} = \hat{\hat v}_{xx}- f_u^*(u^*_0,K_0^*)\hat{\hat u}- f_v^*(u^*_0,K_0^*)\hat{\hat v } \end{aligned} \]</div> <p>Now we find:</p> <div class="math-container">\[ \hat{\hat u} =- \frac{f_v^*}{f_u^*}\hat{\hat v}+\mathcal O(\epsilon^2) \]</div> <p>Because of the constant coefficients, we also get \(\hat{\hat u}_{xx}= - \frac{f_v^*}{f_u^*}\hat{\hat v}_{xx}\) (is this true? can’t higher order terms have \(O(\epsilon^-1)\) derivatives or something like that?) Then we also find by adding the two equations:</p> <div class="math-container">\[ \hat{\hat v}_{xx} =\hat\lambda \epsilon^2(\hat{\hat u}+\hat{\hat v})-\epsilon^2 \hat u_{xx}=\hat\lambda\epsilon^2\frac{f_u^*-f_v^*}{f_u}\hat{\hat v^*}+ \epsilon^2\frac{f_v^*}{f_u^*}\hat{\hat v}_{xx}+\mathcal O(\epsilon^4) \]</div> <p>So we get:</p> <div class="math-container">\[ \hat{\hat v}_{xx}\left(1+\epsilon^2\frac{f_v^*}{f_u^*}\right) =\hat\lambda\epsilon^2\frac{f_u^*-f_v^*}{f_u}\hat{\hat v^*}+\mathcal O(\epsilon^4) \]</div> <p>Now we can just divide by this new term, and get the same expression as for \(2&lt;2\):</p> <div class="math-container">\[ \hat{\hat v}_{xx} =\hat\lambda\epsilon^2\frac{f_u^*-f_v^*}{f_u}\hat{\hat v^*}+\mathcal O(\epsilon^4) \]</div> <h4 id="nu-order-2-fast">Nu order 2 fast</h4> <div class="math-container">\[\begin{aligned} \hat\lambda \epsilon^2 \hat u = \hat u_{\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u+f_v^*(u^*_0,K_0^*)\hat v \\ \hat\lambda \epsilon^{2+2} \hat v = \hat v_{\xi\xi}-\epsilon^2 f_u^*(u^*_0,K_0^*)\hat u-\epsilon^2 f_v^*(u^*_0,K_0^*)\hat v \end{aligned}\]</div> <p>So: \(\hat v=\hat K+\mathcal O(\epsilon^2)\) Then we get the following system:</p> <div class="math-container">\[ \hat\lambda \epsilon^2 \hat u = \hat u_{\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u+f_v^*(u^*_0,K_0^*)\hat K+\mathcal O(\epsilon^2) \\ \]</div> <p>We expand \(\hat u\) as:</p> <div class="math-container">\[\hat u=\hat u_0+\epsilon^2\hat u_1\]</div> <p>and \(\hat K\) as \(\hat K = \epsilon^2 \hat{\hat K}\), order 1 is not possible because of the solvability criterion (Appendix). And obtain at leading order:</p> <div class="math-container">\[ \hat u_{0,\xi\xi}+f_u^*(u_0^*,K_0^*)\hat u_0=0 \]</div> <p>Which we recognize as the homogeneous fast reduced problem, to which \(Au_{0,\xi}^*\) is the solution. For simplicity we set \(A=1\) so we get \(\hat u= u^*_{0,\xi}+\epsilon^2\hat u_1\) So we get at order \(\epsilon^2\):</p> <div class="math-container">\[ \hat\lambda u^*_{0,\xi} = \hat u_{1,\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u_1+f_v^*(u^*_0,K_0^*)\hat{\hat K}+\mathcal O(\epsilon^{2}) \\ \]</div> <p>Which is a homogeneous SL problem with again the same operator \(\mathcal L=\partial_{\xi\xi}+f_u^*(u_0^*,K_0^*)\). The Fredholm alternative tells us that this equations has solutions which obey:</p> <div class="math-container">\[ \langle u_{0,\xi}^*, \hat\lambda u^*_{0,\xi} -f_v^*(u^*_0,K_0^*)\hat{\hat K} \rangle =0 \]</div> <p>Which gives:</p> <div class="math-container">\[ \hat{\hat K} = \hat\lambda \frac{\int_I (u_{0,\xi}^*(\xi))^2d\xi}{\int_I f_v^*(u_0^*(\xi),K_0^*)u_{0,\xi}^*(\xi)d\xi} \]</div> <p>Since \(u_{0,\xi}^*(\xi)\) decays exponentially on both sides, the integrals converge and can be replaced by integrals over the entirety of \(\mathbb R\).</p> <h3 id="andere-techniek-voor-fast-jump-">Andere techniek voor fast jump? :)</h3> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat u = \hat u_{\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u+\epsilon^{2}f_v^*(u^*_0,K_0^*)\hat{\hat v} \\ \hat\lambda \epsilon^{4} \hat{\hat v} = \epsilon^0 \hat{\hat v}_{\xi\xi}-\epsilon^0 f_u^*(u^*_0,K_0^*)\hat u- \epsilon^{2} f_v^*(u^*_0,K_0^*)\hat{\hat v } \end{aligned} \]</div> <p>Again our favorite trick: we add the equations and get:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 \hat u +\hat\lambda \epsilon^{4} \hat{\hat v}= \hat u_{\xi\xi}+\epsilon^0 \hat{\hat v}_{\xi\xi}\end{aligned} \]</div> <p>We expand \(\hat u\) and find:</p> <div class="math-container">\[ \begin{aligned} \hat\lambda \epsilon^2 (u_{0,\xi}^*+\epsilon^2\hat u_1) +\hat\lambda \epsilon^{4} \hat{\hat v}= (u_{0,\xi}^*+\epsilon^2\hat u_1)_{\xi\xi}+\epsilon^0 \hat{\hat v}_{\xi\xi}\end{aligned} \]</div> <p>Integrating this equation, and using the fact that \(u_{0,\xi}^0\) is a heteroclinic orbit, hence the derivatives go to zero for \(\xi\to\pm \infty\), we find:</p> <div class="math-container">\[ \Delta_{fast} \hat{\hat v}_\xi=\begin{aligned} \int\hat{\hat v}_{\xi\xi}d\xi=\epsilon^2\int \hat\lambda u_{0,\xi}^*- \hat u_{1,\xi\xi}d\xi+\mathcal O(\epsilon^4) \end{aligned} \]</div> <p>Note how the integral over the correction might have something to do with the interaction term! The difference in derivatives will be matched to \(\lambda\), hence (possibly) connecting to the velocity of the wave too!</p> <p>From <a href="/update/2024/arjen-notes-(my-interpretation)/">Arjen Notes (my interpretation)</a> we know that:</p> <div class="math-container">\[ \hat\lambda u^*_{0,\xi} = \hat u_{1,\xi\xi}+f_u^*(u^*_0,K_0^*)\hat u_1+f_v^*(u^*_0,K_0^*)\hat{\hat K}+\mathcal O(\epsilon^{2}+\epsilon^{2\nu}) \]</div> <p>As the order \(\epsilon^2\) equation for \(u\). Solving for \(\hat u_1\) and inserting in the equation above then yields:</p> <div class="math-container">\[ \begin{aligned} \Delta_{fast} \hat{\hat v}_\xi=\epsilon^2\int f_u^*(u^*_0,K_0^*)\hat u_1+f_v^*(u^*_0,K_0^*)\hat{\hat K}d\xi+\mathcal O(\epsilon^4) \end{aligned} \]</div> <p>We get an integral condition on the fast jump, which we match to the square root business we found earlier.</p> <p>We get the same equation as Arjen, except the lambda term, but I think he forgot an \(\epsilon^\nu\) there. :)</p> <p>Probleem: integraal convergeert over het algemeen niet? :((</p> <p><a href="/assets/md/Nu is twee!.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Optellen</title><link href="https://leanderhb.github.io/update/2024/optellen/" rel="alternate" type="text/html" title="Optellen"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/optellen</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/optellen/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>We start with the set of equations:</p> <div class="math-container">\[\begin{aligned} U_t &amp;= \epsilon^2U_{xx}+f(U,V)\\ V_t &amp;= V_{xx}-f(U,V) \end{aligned} \]</div> <p>By previous analysis, we know that we get a 1 parameter family in \(K\) of pulses and fronts described by a Hamiltonian system in \(U\), for which there is a specific \(K^*\) for which we obtain a front solution. Take this \(K^*\) and the front \((U^*,V^*)=(U^*,K^*-\epsilon^2 U^*)\) that comes with it. We can expand these values and obtain:</p> <div class="math-container">\[ \begin{aligned} K^*&amp;=K^*_0+\epsilon^2K_1^*+\mathcal O(\epsilon^4)\\ U^*&amp;=U^*_0+\epsilon^2U_1^*+\mathcal O(\epsilon^4)\\ V^*&amp;=V^*_0+\epsilon^2V_1^*+\mathcal O(\epsilon^4) = K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*+\mathcal O(\epsilon^4) \end{aligned} \]</div> <p>Let’s perturb the system to check stability, take \(\delta\) smaller than all system scales, and define:</p> <div class="math-container">\[\begin{aligned} U(\xi) &amp;= U^*(\xi)+\delta \exp(\lambda t)u(\xi)\\ V(\xi) &amp;= V^*(\xi)+\delta \exp(\lambda t)v(\xi) \end{aligned}\]</div> <p>Inserting this into the PDE and throwing out terms of order \(\delta^2\), we get the linearized equations:</p> <div class="math-container">\[ \begin{aligned} \lambda u &amp;= \epsilon^2u_{xx}+f_U(U^*,V^*)u+f_V(U^*,V^*)v\\ \lambda v&amp;= v_{xx}-f_U(U^*,V^*)u-f_V(U^*,V^*)v \end{aligned} \]</div> <p>Completely expanded we find (check order error lieve makker):</p> <div class="math-container">\[ \begin{aligned} \epsilon^2 \hat\lambda (u_0+\epsilon^2 u_1) &amp;= \epsilon^2(u_0+\epsilon^2 u_1)_{xx}+[f_U^* +\epsilon^2f_{UU}^* U_1^*+\epsilon^2f_{UV}^* (K_1^*-U_0^*)](u_0+\epsilon^2 u_1)\\ &amp;+[f_V^* +\epsilon^2f_{VU}^* U_1^*+\epsilon^2f_{VU}^* (K^*_1-U_0^*)](v_0+\epsilon^2 v_1+\epsilon^4 v_2)+\mathcal O(\epsilon^6)\\ \epsilon^2 \hat\lambda (v_0+\epsilon^2 v_1)&amp;= (v_0+\epsilon^2 v_1+\epsilon^4 v_2)_{xx}+[-f_U^* -\epsilon^2f_{UU}^* U_1^*-\epsilon^2f_{UV}^* (K_1^*-U_0^*)](u_0+\epsilon^2 u_1)\\ &amp;+[-f_V^* -\epsilon^2f_{VU}^* U_1^*-\epsilon^2f_{VU}^* (K^*_1-U_0^*)](v_0+\epsilon^2 v_1+\epsilon^4 v_2)+\mathcal O(\epsilon^6)\\ \end{aligned} \]</div> <p>adding these two we get:</p> <div class="math-container">\[ \begin{aligned} \epsilon^2 \hat\lambda (u_0+\epsilon^2 u_1+v_0+\epsilon^2 v_1) &amp;= (\epsilon^2u_0+\epsilon^4 u_1+v_0+\epsilon^2 v_1+\epsilon^4 v_2)_{xx}+O(\epsilon^6)\\ \end{aligned} \]</div> <p>and in the fast coordinate:</p> <div class="math-container">\[ \begin{aligned} \epsilon^4\hat\lambda (u_0+v_0) &amp;= (\epsilon^2u_0+\epsilon^4 u_1+v_0+\epsilon^2 v_1+\epsilon^4 v_2)_{\xi\xi}+O(\epsilon^6)\\ \end{aligned} \]</div> <p>We can now check the equations of all orders:</p> <div class="math-container">\[ \begin{aligned} O(1):\quad 0 &amp;= (v_0)_{\xi\xi}\\ O(\epsilon^2):\quad0 &amp;= (u_0+ v_1)_{\xi\xi}\\ O(\epsilon^4):\quad \hat\lambda (u_0+v_0) &amp;= ( u_1+ v_2)_{\xi\xi}\\ \end{aligned} \]</div> <p>Via Fredholm alternative, and \(O(1)\) \(u\) equations, we need \(v_0=0\). Then this reduces to:</p> <div class="math-container">\[ \begin{aligned} O(1):\quad v_0&amp;=0\\ O(\epsilon^2):\quad0 &amp;= (u_0+ v_1)_{\xi\xi}\\ O(\epsilon^4):\quad \hat\lambda u_0 &amp;= ( u_1+ v_2)_{\xi\xi}\\ \end{aligned} \]</div> <p>Furthermore, we know that \(u_0=U^*_{0,\xi}\) solves the equation, so we can assume we know \(u_0\). Then we also know \(v_1\) (integration constant = 0 because Fredholm?). Unknowns are then \(u_1,v_2\), which will in essence be the first order correction to the translational mode. The question is if this correction will then push \(\lambda\) into the positive or negative region. So all that’s left is to solve \(u_1\), then we should find \(v_2\) by the third equation. The equation for \(u_1\) is the following:</p> <div class="math-container">\[ \hat\lambda u_0 = u_{1,\xi\xi}+f_U^* u_1+[ f_{UU}^* U_1^*+f_{UV}^* (K_1^*-U_0^*)]u_0+ v_1f_V^* \]</div> <p>In principle, the operator is the same as what we found earlier:</p> <div class="math-container">\[ u_1 = \mathcal L^{-1}g(\xi) \]</div> <p>Where \(g(\xi)\) is:</p> <div class="math-container">\[ \]</div> <h1 id="equations-for-u_1-etc">Equations for \(U_1^*\) etc</h1> <div class="math-container">\[ \begin{aligned} 0 &amp;= \epsilon^2U^*_{xx}+f(U^*,V^*)\\ 0 &amp;= V^*_{xx}-f(U^*,V^*) \end{aligned} \]</div> <p>We expand with:</p> <div class="math-container">\[ \begin{aligned} K^*&amp;=K^*_0+\epsilon^2K_1^*+\mathcal O(\epsilon^4)\\ U^*&amp;=U^*_0+\epsilon^2U_1^*+\mathcal O(\epsilon^4)\\ V^*&amp;=V^*_0+\epsilon^2V_1^*+\mathcal O(\epsilon^4) = K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*+\mathcal O(\epsilon^4) \end{aligned} \]</div> <p>Then we get:</p> <div class="math-container">\[ \begin{aligned} 0 &amp;= \epsilon^2(U^*_0+\epsilon^2U_1^*)_{xx}+f(U^*_0+\epsilon^2U_1^*,K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*)\\ 0 &amp;= (K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*)_{xx}-f(U^*_0+\epsilon^2U_1^*,K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*) \end{aligned} \]</div> <p>we can add the equations and obtain:</p> <div class="math-container">\[ \begin{aligned} 0 &amp;= \epsilon^2(U^*_0+\epsilon^2U_1^*)_{xx}+(K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*)_{xx}\\ \end{aligned} \]</div> <p>In the fast coordinates:</p> <div class="math-container">\[ \begin{aligned} 0 &amp;= (U^*_0+\epsilon^2U_1^*)_{\xi\xi}+f(U^*_0+\epsilon^2U_1^*,K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*)\\ 0 &amp;= (K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*)_{\xi\xi}-\epsilon^2f(U^*_0+\epsilon^2U_1^*,K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*) \end{aligned} \]</div> <p>expanding:</p> <div class="math-container">\[ \begin{aligned} f(U^*_0+\epsilon^2U_1^*,K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*) = \\ f(U^*_0,K^*_0)+\epsilon^2f_U(U^*_0,K^*_0)U_1^*+\epsilon^2f_V(U^*_0,K^*_0)( K_1^*- U_0^*) \end{aligned} \]</div> <p>collecting powers:</p> <div class="math-container">\[ \begin{aligned} 0 &amp;= (U^*_0+\epsilon^2U_1^*)_{\xi\xi}+f(U^*_0,K^*_0)+\epsilon^2f_U(U^*_0,K^*_0)U_1^*+\epsilon^2f_V(U^*_0,K^*_0)( K_1^*- U_0^*)\\ 0 &amp;= (K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*)_{\xi\xi}-\epsilon^2f(U^*_0+\epsilon^2U_1^*,K^*_0+\epsilon^2 K_1^*-\epsilon^2 U_0^*) \end{aligned} \]</div> <p>collecting for real (second eqn not important?)</p> <div class="math-container">\[ \begin{aligned} 0 &amp;= (U^*_0)_{\xi\xi}+f(U^*_0,K^*_0)\\ 0 &amp;= (U_1^*)_{\xi\xi}+f_U(U^*_0,K^*_0)U_1^*+f_V(U^*_0,K^*_0)( K_1^*- U_0^*)\\ \end{aligned} \]</div> <p>Fredholm tells us:</p> <div class="math-container">\[ K_1^* = \frac{\int U^*_0 U^*_{0,\xi} f_V^*}{\int U^*_{0,\xi} f_V^*} \]</div> <p>Let’s take the derivative of the second equation:</p> <div class="math-container">\[ \begin{aligned} 0 &amp;= \partial_\xi(U_1^*)_{\xi\xi} \\ &amp;+\partial_\xi (f_U(U^*_0,K^*_0)U_1^*)\\ &amp;+\partial_\xi(f_V(U^*_0,K^*_0)( K_1^*- U_0^*))\\ &amp;= (U_1^*)_{\xi\xi\xi} \\ &amp;+ f_{UU}(U^*_0,K^*_0)U^*_{0,\xi}U_1^*+f_U(U^*_0,K^*_0)U_{1,\xi}^*\\ &amp;+f_{UV}(U^*_0,K^*_0)U^*_{0,\xi}( K_1^*- U_0^*)+f_V(U^*_0,K^*_0)( - U_{0,\xi}^*)\\ \end{aligned} \]</div> <p>Now we look at our original equation for \(u_1\):</p> <div class="math-container">\[ \hat\lambda u_0 = u_{1,\xi\xi}+f_U^* u_1+[ f_{UU}^* U_1^*+f_{UV}^* (K_1^*-U_0^*)]u_0+ v_1f_V^* \]</div> <p>and we recognize a lot of terms. Let’s write our derivative-equation as follows:</p> <div class="math-container">\[ \begin{aligned} 0 &amp;= (U_1^*)_{\xi\xi\xi}+f_U^*U_{1,\xi}^* + [f_{UU}^* U_1^*+f_{UV}^*( K_1^*- U_0^*)-f_V^*] u_0\\ \end{aligned} \]</div> <p>Finally, note that \(v_1=-u_0\) as we found earlier. Then we can replace a lot of terms and end up with:</p> <div class="math-container">\[ \hat\lambda u_0 = u_{1,\xi\xi}+f_U^* u_1-[U_{1,\xi\xi\xi}^*+f_U^*U_{1,\xi}^*] \]</div> <p>This seems nice, we got rid of the annoying second derivatives and we don’t need \(K_1\) anymore. However, we are now stuck with \(U_1\). So, let’s use the Fredholm alternative to find that solutions should satisfy:</p> <div class="math-container">\[ \langle \hat\lambda u_0 +U_{1,\xi\xi\xi}^*+f_U^*U_{1,\xi}^*,u_0\rangle = 0 \]</div> <p>Since \(u_0\) goes to zero exponentially, we can maybe use partial integration to find some relations. Something else we could do is fill our result into the equation for \(\Delta v_\xi\) <a href="/update/2024/netjes-order-nu=2/">Netjes order nu=2</a> and we get: (does this integral converge? can i replace with over entire R?)</p> <div class="math-container">\[ \begin{aligned} \Delta_{fast} v_{\xi}^*&amp;=\epsilon^4\int_\mathbb R [\hat\lambda u_0-u_{1,\xi\xi}]d\xi+O(\epsilon^6) \end{aligned} \]</div> <p>Then we find after filling in:</p> <div class="math-container">\[ \begin{aligned} \Delta_{fast} v_{\xi}^*&amp;=\epsilon^4\int_\mathbb R [\hat\lambda f_U^* u_1-[U_{1,\xi\xi\xi}^*+f_U^*U_{1,\xi}^*]]d\xi+O(\epsilon^6) \end{aligned} \]</div> <p>The integral over \(U^*_{1,\xi\xi\xi}\) will be zero, by the boundary conditions, so we’re left with:</p> <div class="math-container">\[ \begin{aligned} \Delta_{fast} v_{\xi}^*&amp;=\epsilon^4\int_\mathbb R [\hat\lambda f_U^* u_1-f_U^*U_{1,\xi}^*]d\xi+O(\epsilon^6) \end{aligned} \]</div> <p>oke maar waarom doe ik moeilijk, kan niet gewoon \(\Delta_{fast}(v+u)_\xi\) gematched worden?</p> <p><a href="/assets/md/Optellen.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Thesis todo</title><link href="https://leanderhb.github.io/update/2024/thesis-todo/" rel="alternate" type="text/html" title="Thesis todo"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/thesis-todo</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/thesis-todo/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <h2 id="eerste-deel-stability-of-single-front-solution">Eerste deel: stability of single front solution</h2> <ul> <li>Prove rigorous that solutions exist: Hamiltonian, twee punten op zelfde potential, en ertussen strict lagere potential? Wat gebeurd er de andere kant op (altijd unbounded? of zijn het pulse oplossingen bovenop de plateaus?).</li> <li>Prove linear stability <h4 id="linear-stab---nonlinear-stab-">linear stab -&gt; nonlinear stab <img src="/assets/images/Pasted image 20240221132443.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240221132443.png"/><img src="/assets/images/Pasted image 20240221133412.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240221133412.png"/></h4> <p>sprong som Bates &amp; Jones [2] van Alexanders - Topological inv…</p> </li> </ul> <h4 id="intuitie-uit-simulaties">intuitie uit simulaties:</h4> <p>Klopt het dat als lokaal \(\eta&gt;\eta_0\), dan gaat kapot/heel? Klinkt logisch omdat het dan een homoclinic orbit wordt die de boel verbind, die dan stabiel/instabiel kan zijn! Interacties gebeuren wss niet op de FBS</p> <h4 id="natuurkunde-variant">Natuurkunde variant</h4> <p>Theorie scattering, zwak potentiaal</p> <h4 id="flip-u-en-v-in-analyse-dat-lijkt-standaard-en-ga-naar-hoofdletters-u-en-v-zodat-de-linearized-versies-met-kleine-letter-kunnen">Flip u en v in analyse, dat lijkt standaard, en ga naar hoofdletters U en V, zodat de linearized versies met kleine letter kunnen.</h4> <h3 id="ideetjes">ideetjes</h3> <p>som van twee fronten wordt approx een puls, gebruik dan symmetrie etc om analyse ter vergemakkelijken? I dunno, mogelijk handig</p> <h3 id="admin">Admin</h3> <ul> <li>Second exam voor math+phys</li> <li>research proposal</li> <li>planning??</li> <li>hoe beoordeling? want math+physics zijn niet eens</li> <li>hoe werkt physics seminar</li> <li>wordt ik genaaid omdat ik al ben begonnen?</li> <li>Math seminar presentatie?? (mail ale)</li> <li>welke site? DuMa of beide</li> </ul> <h3 id="wijze-lessen-van-paper-jacht">wijze lessen van paper-jacht</h3> <p>Natuurkunde papers zijn er wel, meer hands on enzo Iedereen obsessed over S-shaped f, maar is dat nodig wanneer mass conserved is? moet ik traveling waves bekijken? Maakt schaling \(\tau\) uit? lijkt er wel op helaas, vgm niet weg te schalen in de functie, maar wel moeite waard om dat uit te zoeken. NISHIURA doet coole shit met SLEP condition, 1 physics paper gebruikt dat, nice</p> <p><a href="/assets/md/Thesis todo.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Thesis</title><link href="https://leanderhb.github.io/update/2024/thesis/" rel="alternate" type="text/html" title="Thesis"/><published>2024-10-02T00:00:00+00:00</published><updated>2024-10-02T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/thesis</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/thesis/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <div class="math-container">\[ \begin{align} u_t = f(u,v)+\delta\Delta u\\ v_t = -f(u,v)+\Delta v \end{align} \]</div> <p>Now consider \(u_t=v_t=0\), then:</p> <div class="math-container">\[ \begin{align} 0 = f(u,v)+\delta\Delta u\\ 0 = -f(u,v)+\Delta v \end{align} \]</div> <p>Just add these two expressions to obtain:</p> <div class="math-container">\[ \begin{align} 0 = f(u,v)+\delta\Delta u-f(u,v)+\Delta v\\ 0=\delta \Delta u+\Delta v\implies \Delta v=\delta \Delta u \end{align} \]</div> <p>Now also:</p> <div class="math-container">\[ \begin{align} 0 = f(u,v)+\delta\Delta u\\ 0 = -f(u,v)+\Delta v \end{align} \]</div> <p><img src="/assets/images/Pasted image 20231201202900.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20231201202900.png"/> <img src="/assets/images/Pasted image 20231201202910.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20231201202910.png"/></p> <h1 id="vragen">Vragen</h1> <ul> <li>is er een soort theorie om van systeem integraal vergelijking te maken? (En is dat nuttig?)</li> <li>en dan lokale operator norm oid te definieren</li> <li>plaatje klopt niet met <a href="https://www.wolframalpha.com/input?i=ContourPlot%5Bu*v+-+%284*u%29%2F%28u+%2B+2%29+%3D+0%2C+%7Bu%2C+0%2C+10%7D%2C+%7Bv%2C+0%2C+10%7D%5D">formule: link</a>?</li> <li></li> </ul> <p><img src="/assets/images/Pasted image 20231206133814.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20231206133814.png"/></p> <p>[53] V. Maz’ya, J. Rossmann, On the Agmon–Miranda maximum principle for solutions of strongly elliptic equa- tions in domains of R n with conical points, Ann. Global Anal. Geom. 10 (1992) 125–150</p> <p><img src="/assets/images/Pasted image 20240127230545.png" class="img-fluid rounded z-depth-1" alt="Pasted image 20240127230545.png"/></p> <p><a href="/assets/md/Thesis.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">3.1.11</title><link href="https://leanderhb.github.io/update/2024/3.1.11/" rel="alternate" type="text/html" title="3.1.11"/><published>2024-10-01T00:00:00+00:00</published><updated>2024-10-01T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/3.1.11</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/3.1.11/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <p>Theorem 3.1.11. Assume that operator \(\mathcal{L}\) given in (3.1.1) is exponentially asymptotic with \(H^1(\mathbb{R})\) coefficients. Then \(\mathcal{L}\) is a relatively compact perturbation of the asymptotic operator \(\mathcal{L}_{\infty}\) given in (3.1.2). In particular,</p> <div class="math-container">\[ \sigma_{\text {ess }}(\mathcal{L})=\left\{\lambda \in \mathbb{C} \mid i_{-}(\lambda) \neq \mathrm{i}_{+}(\lambda)\right\} \cup\left\{\lambda \in \mathbb{C} \mid \operatorname{dim} \mathbb{E}^{\mathrm{c}}\left(A_{ \pm}(\lambda)\right) \neq 0\right\} \]</div> <p>Moreover, for each \(\lambda \notin \sigma_{\text {ess }}(\mathcal{L})\), either \(\operatorname{dim}(\operatorname{ker}(\mathcal{L}-\lambda)) \neq 0\) or there exists \(C&gt;0\) such that</p> <div class="math-container">\[ \left\|(\mathcal{L}-\lambda)^{-1} f\right\|_{H^n(\mathbb{R})} \leq C\|f\|_{L^2(\mathbb{R})} \]</div> <p>Proof. We consider only the case that the coefficients \(a_j(x)\) of \(\mathcal{L}\) are constant except on a common, compact interval \(I \subset \mathbb{R}\). To see that \(\mathcal{L}\) is a relatively compact perturbation of \(\mathcal{L}_{\infty}\), fix \(\lambda \in \rho\left(\mathcal{L}_{\infty}\right)\) and observe that the \(n\) th-order derivatives in \(\mathcal{L}_{\infty}-\mathcal{L}\) cancel, and setting aside the discontinuity at \(x=0\), we view the operator \(\mathcal{L}_{\infty}-\mathcal{L}\) as a piecewise map from \(H^n(\mathbb{R})\) into \(H^1\left(\mathbb{R}_{+}\right)\)and into \(H^1\left(\mathbb{R}_{-}\right)\). From Lemma 3.1 .10 we know that \(\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}: L^2(\mathbb{R}) \mapsto H^n(\mathbb{R})\) is continuous, so that the composite map \(\left(\mathcal{L}_{\infty}-\mathcal{L}\right)\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}: L^2(\mathbb{R}) \mapsto\) \(H^1\left(\mathbb{R}_{+}\right) \oplus H^1\left(\mathbb{R}_{-}\right)\)is continuous. Since the coefficients \(a_j(x)\) of \(\mathcal{L}\) are constant off \(I \subset \mathbb{R},\left(\mathcal{L}_{\infty}-\mathcal{L}\right)\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}: L^2(\mathbb{R}) \mapsto H^1\left(I_{+}\right) \oplus H^1\left(I_{-}\right)\)where \(I_{-}=I \cap(-\infty, 0]\) and \(I_{+}=I \cap[0, \infty)\). In particular the map takes bounded sets to bounded sets. As bounded sets in \(H^1\left(I_{ \pm}\right)\) are equicontinuous and \(I_{ \pm}\)are compact, we deduce from the Arzela-Ascoli theorem that the operator \(\left(\mathcal{L}_{\infty}-\mathcal{L}\right)\left(\mathcal{L}_{\infty}-\lambda\right)^{-1}\) maps bounded sets of \(L^2(\mathbb{R})\) into precompact sets, and hence is compact. The characterization of the essential spectrum of \(\mathcal{L}\) follows from the Weyl’s essential spectrum Theorem 2.2.6 and Lemma 3.1.10. The statement (3.1.17) follows from the Fredholm alternative since \(\mathcal{L}-\lambda: H^n(\mathbb{R}) \rightarrow L^2(\mathbb{R})\) is Fredholm of index zero for \(\lambda \notin \sigma_{\text {ess }}(\mathcal{L})\).</p> <p><a href="/assets/md/3.1.11.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Proberen operator als perturbed</title><link href="https://leanderhb.github.io/update/2024/proberen-operator-als-perturbed/" rel="alternate" type="text/html" title="Proberen operator als perturbed"/><published>2024-10-01T00:00:00+00:00</published><updated>2024-10-01T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/proberen-operator-als-perturbed</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/proberen-operator-als-perturbed/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <div class="math-container">\[ \mathcal L = \mathcal L_0+\epsilon \mathcal L_1+\dots \]</div> <div class="math-container">\[ \lambda\begin{pmatrix}u\\v\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u\\v\end{pmatrix} \]</div> <p>expanding:</p> <div class="math-container">\[ (\lambda_0+\epsilon^2\lambda_1+\dots)\begin{pmatrix}u_0+\epsilon^2 u_1+\dots\\ v_0+\epsilon^2 v_1+\epsilon^4 v_2+\dots\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ \epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u_0+\epsilon^2 u_1+\dots\\ v_0+\epsilon^2 v_1+\epsilon^4 v_2+\dots\end{pmatrix} \]</div> <p>collecting powers</p> <div class="math-container">\[ \lambda\begin{pmatrix}u\\v\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ 0&amp;\partial_{\xi\xi} \end{pmatrix} \begin{pmatrix}u\\v\end{pmatrix} \]</div> <div class="math-container">\[ \lambda\begin{pmatrix}v+\epsilon^2 u\\v\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \begin{pmatrix}u\\v\end{pmatrix} \]</div> <p>dus:</p> <div class="math-container">\[ \mathcal L = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \]</div> <div class="math-container">\[ v+\epsilon^2 u = \epsilon^2\partial_{\xi\xi} u+\partial_{\xi\xi}v+0 \]</div> <h1 id="expansion">expansion</h1> <div class="math-container">\[ \lambda_0\begin{pmatrix}u_0\\ u_0+v_1\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;0 \\ 0&amp;\partial_{\xi\xi} \end{pmatrix} \begin{pmatrix}u_0\\u_0+ v_1\end{pmatrix} \]</div> <div class="math-container">\[ \hat\lambda \begin{pmatrix}u_1\\ u_1+v_2\end{pmatrix} = \begin{pmatrix}\partial_{\xi\xi}+f^*_U-f_V^*&amp;f_V^* \\ 0&amp;\partial_{\xi\xi} \end{pmatrix} \begin{pmatrix}u_1\\u_1+ v_2\end{pmatrix} \]</div> <p>Got it! You want to express the original system in the form of a first-order differential equation involving a 4-component vector. Let’s proceed.</p> <p>We start by rewriting the system in a way that uses a first-order form for (\partial_\xi). Define:</p> <p>[ \mathbf{p} = \begin{pmatrix} u \ v \ u_\xi \ v_\xi \end{pmatrix} ]</p> <p>Now, differentiate (\mathbf{p}) with respect to (\xi):</p> <p>[ \mathbf{p}<em>\xi = \begin{pmatrix} u</em>\xi \ v_\xi \ u_{\xi\xi} \ v_{\xi\xi} \end{pmatrix} ]</p> <p>We know the original equations involve second-order derivatives of (u) and (v). Rewrite them to relate these to the components of (\mathbf{p}):</p> <p>From:</p> <ol> <li>(\lambda u = (\partial_{\xi\xi} + f^<em>_U) u + f_V^</em> v)</li> </ol> <p>We can express the second derivative (u_{\xi\xi}) as:</p> <p>[ u_{\xi\xi} = \lambda u - f^<em>_U u - f_V^</em> v ]</p> <p>Similarly, from:</p> <ol> <li>(\lambda v = -\epsilon^2 f^<em>_U u + (\partial_{\xi\xi} - \epsilon^2 f_V^</em>) v)</li> </ol> <p>We get:</p> <p>[ v_{\xi\xi} = \lambda v + \epsilon^2 f^<em>_U u + \epsilon^2 f_V^</em> v ]</p> <p>Now, we can write this in matrix form as:</p> <p>[ \mathbf{p}_\xi = A \mathbf{p} ]</p> <p>where:</p> <p>[ A = \begin{pmatrix} 0 &amp; 0 &amp; 1 &amp; 0 <br/> 0 &amp; 0 &amp; 0 &amp; 1 <br/> \lambda - f^<em>_U &amp; -f_V^</em> &amp; 0 &amp; 0 <br/> \epsilon^2 f^<em>_U &amp; \lambda + \epsilon^2 f_V^</em> &amp; 0 &amp; 0 \end{pmatrix} ]</p> <p>Thus:</p> <p>[ \mathbf{p}_\xi = A \mathbf{p} ]</p> <p>This expresses the original system as a first-order differential equation in terms of a 4-component vector (\mathbf{p}).</p> <p><a href="/assets/md/Proberen operator als perturbed.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Weyl voor niet-compact poging</title><link href="https://leanderhb.github.io/update/2024/weyl-voor-niet-compact-poging/" rel="alternate" type="text/html" title="Weyl voor niet-compact poging"/><published>2024-10-01T00:00:00+00:00</published><updated>2024-10-01T00:00:00+00:00</updated><id>https://leanderhb.github.io/update/2024/weyl-voor-niet-compact-poging</id><content type="html" xml:base="https://leanderhb.github.io/update/2024/weyl-voor-niet-compact-poging/"><![CDATA[<style>.math-container{max-width:100%;overflow-x:auto;white-space:nowrap}</style> <div class="math-container">\[ \mathcal L-\mathcal L_\infty \]</div> <div class="math-container">\[ \mathcal L = \begin{pmatrix}\partial_{\xi\xi}+f^*_U&amp;f_V^* \\ -\epsilon^2 f^*_U&amp;\partial_{\xi\xi}-\epsilon^2 f_V^* \end{pmatrix} \]</div> <p>Dus:</p> <div class="math-container">\[ \mathcal L-\mathcal L_\infty = \begin{pmatrix}f^*_U(x)-&amp;f_V^*(x) \\ -f^*_U(x)&amp;f_V^*- f_V^*(x) \end{pmatrix} \]</div> <div class="math-container">\[ \mathcal L-\mathcal L_\infty = \begin{pmatrix}a(x)-a_\pm&amp;b(x)-b_\pm \\ -a(x)+a_\pm&amp;-b(x)+b_\pm \end{pmatrix} \]</div> <div class="math-container">\[ (\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}(u,v) = \]</div> <div class="math-container">\[ \|(\mathcal L_\infty-\lambda)^{-1}\| \leq C(\lambda)\|f\| \]</div> <p>Take weakest decay in \(\mathcal L-\mathcal L_\infty\), call it \(\alpha\), then:</p> <div class="math-container">\[ \|(\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}w \|\leq \|(\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}w \| \]</div> <div class="math-container">\[ \int |(\mathcal L-\mathcal L_\infty)(\mathcal L_\infty-\lambda)^{-1}w |^2dx= \]</div> <p><a href="/assets/md/Weyl voor niet-compact poging.md">View Raw Markdown</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry></feed>